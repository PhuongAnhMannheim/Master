{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "from requests import get\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import sqlite3\n",
    "import logging\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Input/ Output\n",
    "db_path = '../Data/test.db'\n",
    "db_name = 'test'\n",
    "log_path = '../Logs/test.log'\n",
    "conn = sqlite3.connect(db_path)\n",
    "c = conn.cursor()\n",
    "c.execute((\"\"\"\n",
    "       CREATE TABLE IF NOT EXISTS\n",
    "           test(\n",
    "               NODE TEXT,\n",
    "               URL TEXT,\n",
    "               REVIEWBODY TEXT,\n",
    "               RATING TEXT,\n",
    "               REVIEWRATING TEXT,\n",
    "               BESTRATING TEXT,\n",
    "               WORSTRATING TEXT,\n",
    "               PRIMARY KEY (NODE, URL))\n",
    "   \"\"\"))\n",
    "\n",
    "# Input\n",
    "current_file = 'already_links_in/deepfocusreview.txt'\n",
    "current_reviews = set(line.strip() for line in open(current_file))\n",
    "\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename=log_path, mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1129\n"
     ]
    }
   ],
   "source": [
    "print(len(current_reviews))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870\n"
     ]
    }
   ],
   "source": [
    "host = \"https://thereviewmonk.com/\"\n",
    "review_count = 0\n",
    "no_annotation = 0\n",
    "no_rating = 0\n",
    "already_count = 0\n",
    "problem_count = 0\n",
    "\n",
    "def generateNode(length):\n",
    "    letters_and_digits = string.ascii_letters +  string.digits\n",
    "    result_str = ''.join((random.choice(letters_and_digits) for i in range(length)))\n",
    "    node = \"_:znode\" + result_str\n",
    "    return node\n",
    "\n",
    "# for i in current_reviews:\n",
    "#     print(i)\n",
    "for character in string.ascii_lowercase + '0':\n",
    "    url = f'https://deepfocusreview.com/reviews/?id={character}'\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    for entry in soup.find_all('ol', id='reviewalpha-list'):\n",
    "        for link in entry.find_all('li'):\n",
    "            # print(link.a['href'])\n",
    "            review_count += 1\n",
    "\n",
    "print(review_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already in\n"
     ]
    }
   ],
   "source": [
    "review_link='https://deepfocusreview.com/reviews/shutter-island/'\n",
    "if review_link in current_reviews:\n",
    "    print('already in')\n",
    "    pass\n",
    "else:\n",
    "    response = get(review_link)\n",
    "    if response.status_code != 200:\n",
    "        problem_count += 1\n",
    "        # print(review_link)\n",
    "    else:\n",
    "        review_soup = BeautifulSoup(response.text, 'lxml')\n",
    "        # print(review_soup)\n",
    "        node = generateNode(31)\n",
    "        url = review_link\n",
    "        reviewBody = \"\"\n",
    "        for i in review_soup.find_all('div', itemprop='reviewBody'):\n",
    "            for j in i.find_all('p'):\n",
    "                reviewBody = reviewBody + j.getText()\n",
    "\n",
    "        ratingValue = review_soup.find('meta', itemprop='ratingValue')['content']\n",
    "        worstRating = review_soup.find('meta', itemprop='worstRating')['content']\n",
    "        bestRating = review_soup.find('meta', itemprop='bestRating')['content']\n",
    "        reviewRating = \"already included\"\n",
    "\n",
    "        print('node:' + node)\n",
    "        print('url: '+ review_link)\n",
    "        print('reviewBody: ' + reviewBody)\n",
    "        print('worstRating: ' + worstRating)\n",
    "        print('bestRating: ' + bestRating)\n",
    "        print('ratingValue: ' + ratingValue)\n",
    "\n",
    "        c.execute(f\"INSERT OR IGNORE INTO {db_name} (NODE, URL, REVIEWBODY, RATING, REVIEWRATING, BESTRATING, WORSTRATING) VALUES (?,?,?,?,?,?,?);\",(node,review_link,reviewBody,str(reviewRating),ratingValue,bestRating,worstRating))\n",
    "        conn.commit()\n",
    "\n",
    "# print(f\"Done {host} - Reviews extracted: \" + str(review_count) + \", without Rating: \" + str(no_rating) + \", problems: \" + str(problem_count))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# host = 'https://www.telegraph.co.uk/'\n",
    "# url = 'https://www.telegraph.co.uk/films/reviews/page-33/'\n",
    "# soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "# movie_container = soup.find_all(\"div\", class_=\"card__content\")\n",
    "# # print(movie_container)\n",
    "# for link in movie_container:\n",
    "#     # print(link)\n",
    "#     # print(link.a['href'])\n",
    "#     review_link = host + link.a['href']\n",
    "#     # if not \"movie-reviews\" in review_link:\n",
    "#     #     pass\n",
    "#     # else:\n",
    "#     print(review_link)\n",
    "\n",
    "#     # print(link.get('href'))\n",
    "#     if review_link is not None:\n",
    "#         if review_link.endswith('html'):\n",
    "#             review_soup = BeautifulSoup(get(review_link).text, 'lxml')\n",
    "#             review_html = review_soup.find(\"div\", itemtype=\"http://schema.org/Review\")\n",
    "#             # print(review_html)\n",
    "#             reviewBody = \"\"\n",
    "#             if review_html is None:\n",
    "#                 print(\"Kein Review Annotation\")\n",
    "#                 no_annotation += 1\n",
    "#             else:\n",
    "#                 reviewBody_html = review_html.find_all(\"div\", class_=\"reviewtext\")\n",
    "#                 reviewRating = review_soup.find(\"div\", itemtype=\"http://schema.org/Rating\")\n",
    "#                 for item in reviewBody_html:\n",
    "#                     reviewBody += item.p.text\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "# Snippets\n",
    "#\n",
    "# def generateNode(length):\n",
    "#     letters_and_digits = string.ascii_letters +  string.digits\n",
    "#     result_str = ''.join((random.choice(letters_and_digits) for i in range(length)))\n",
    "#     node = \"_:znode\" + result_str\n",
    "#     return node\n",
    "\n",
    "    # node = generateNode(31)\n",
    "\n",
    "# for page in range(1, 414):\n",
    "#     url = f'https://www.rollingstone.com/movies/movie-reviews/page/{page}/'\n",
    "\n",
    "# review_soup = BeautifulSoup(get(review_link).text, 'lxml')\n",
    "# review_html = review_soup.find(\"div\", itemtype=\"http://schema.org/Review\")\n",
    "# review_html = review_soup.find(id=\"pmc-movie-review-snippet\")\n",
    "\n",
    "# response = get(review_link, headers={'User-Agent': 'Custom'})\n",
    "# if response.status_code == 404:\n",
    "#     fail_lst.append(review_link)\n",
    "\n",
    "# for item in review_html:\n",
    "#     jsonExtract = str(item).split('\\n')[2].replace(\";\", \"\")\n",
    "#     data = json.loads(\"\".join(jsonExtract))\n",
    "\n",
    "    # reviewBody = data['description']\n",
    "    # ratingValue = str(data['reviewRating']['ratingValue'])\n",
    "    # bestRating = str(data['reviewRating']['bestRating'])\n",
    "    # worstRating = str(data['reviewRating']['worstRating'])\n",
    "    # reviewRating = \"already included\"\n",
    "\n",
    "# data = json.loads(\"\".join(review_soup.find(\"script\", type=\"application/ld+json\").contents))\n",
    "# data = json.loads(\"\".join(review_soup.find(\"script\", {\"type\": \"application/ld+json\"}).contents),strict=False)\n",
    "\n",
    "# reviewBody_html = review_html.find_all(\"div\", class_=\"reviewtext\")\n",
    "\n",
    "# reviewRating = review_soup.find(\"div\", itemtype=\"http://schema.org/Rating\")\n",
    "\n",
    "# reviewBody += item.p.text\n",
    "\n",
    "# worstRating = reviewRating.find(\"meta\", itemprop=\"worstRating\")[\"content\"]\n",
    "# bestRating = reviewRating.find(\"meta\", itemprop=\"bestRating\")[\"content\"]\n",
    "# ratingValue = reviewRating.find(\"meta\", itemprop=\"ratingValue\")[\"content\"]\n",
    "\n",
    "# print('node:' + node)\n",
    "# print('url: '+ review_link)\n",
    "# print('reviewBody: ' + reviewBody)\n",
    "# print('worstRating: ' + worstRating)\n",
    "# print('bestRating: ' + bestRating)\n",
    "# print('ratingValue: ' + ratingValue)\n",
    "\n",
    "# c.execute(f\"INSERT OR IGNORE INTO {db_name} (NODE, URL, REVIEWBODY, RATING, REVIEWRATING, BESTRATING, WORSTRATING) VALUES (?,?,?,?,?,?,?);\",(node,review_link,reviewBody,str(reviewRating),ratingValue,bestRating,worstRating))\n",
    "# conn.commit()\n",
    "\n",
    "# soup = BeautifulSoup(get(url).text, 'html.parser')\n",
    "# movie_container = soup.find_all(\"div\", class_=\"entry post clearfix\")\n",
    "# for link in movie_container[0].find_all(\"a\"):\n",
    "#     review_link = link.get('href')\n",
    "#     print(link.get('href'))\n",
    "#     if review_link is not None:\n",
    "#         if review_link.endswith('html'):\n",
    "#             if review_link in current_reviews:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 print(review_link)\n",
    "#                 manche haben schema.org/Review nicht drin\n",
    "#                 review_count += 1\n",
    "#         if review_link.endswith('html') & review_link not in current_reviews:\n",
    "#             print(review_link)\n",
    "#         else:\n",
    "#             pass\n",
    "#                 #nicht alle Einträge sind vollständig (fehlende Bewertung)\n",
    "#                 # review_count += 1\n",
    "#     else:\n",
    "#         pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}