{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "from requests import get\n",
    "from requests_html import HTMLSession\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import sqlite3\n",
    "import logging\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Input/ Output\n",
    "db_path = '../Data/test.db'\n",
    "db_name = 'test'\n",
    "log_path = '../Logs/test.log'\n",
    "conn = sqlite3.connect(db_path)\n",
    "c = conn.cursor()\n",
    "# c.execute((\"\"\"\n",
    "#        CREATE TABLE IF NOT EXISTS\n",
    "#            test(\n",
    "#                NODE TEXT,\n",
    "#                URL TEXT,\n",
    "#                REVIEWBODY TEXT,\n",
    "#                RATING TEXT,\n",
    "#                REVIEWRATING TEXT,\n",
    "#                BESTRATING TEXT,\n",
    "#                WORSTRATING TEXT,\n",
    "#                PRIMARY KEY (NODE, URL))\n",
    "#    \"\"\"))\n",
    "\n",
    "# Input\n",
    "# current_file = 'already_links_in/deepfocusreview.txt'\n",
    "# current_reviews = set(line.strip() for line in open(current_file))\n",
    "\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename=log_path, mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1129\n"
     ]
    }
   ],
   "source": [
    "# print(len(current_reviews))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\n"
     ]
    }
   ],
   "source": [
    "host = \"https://www.cnet.com\"\n",
    "review_count = 0\n",
    "no_annotation = 0\n",
    "no_rating = 0\n",
    "already_count = 0\n",
    "problem_count = 0\n",
    "\n",
    "def generateNode(length):\n",
    "    letters_and_digits = string.ascii_letters +  string.digits\n",
    "    result_str = ''.join((random.choice(letters_and_digits) for i in range(length)))\n",
    "    node = \"_:znode\" + result_str\n",
    "    return node\n",
    "\n",
    "links = []\n",
    "for page in range(1, 23):\n",
    "    url = f'https://www.proporta.com/devices?p={page}/'\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    lefts = soup.find_all('li', class_='item first')\n",
    "    for left in lefts:\n",
    "        links.append(left.a['href'] + '#allReviews')\n",
    "    rights = soup.find_all('li', class_='item last')\n",
    "    for right in rights:\n",
    "        links.append(right.a['href'] + '#allReviews')\n",
    "for page in range(1, 23):\n",
    "    url = f'https://www.proporta.com/devices?p={page}/'\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    lefts = soup.find_all('li', class_='item first')\n",
    "    for left in lefts:\n",
    "        links.append(left.a['href'] + '#allReviews')\n",
    "    rights = soup.find_all('li', class_='item last')\n",
    "    for right in rights:\n",
    "        links.append(right.a['href'] + '#allReviews')\n",
    "print(len(links))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.proporta.com/ted-baker-mirror-case-for-iphone-xr-leyyaa#allReviews\n"
     ]
    }
   ],
   "source": [
    "print(links[3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-10-09\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-09-27\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-29\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-28\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-28\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-28\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-28\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-28\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-25\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-25\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-25\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-25\" itemprop=\"datePublished\"/>\n",
      "<meta content=\"2019-08-25\" itemprop=\"datePublished\"/>\n"
     ]
    }
   ],
   "source": [
    "# review_link='https://www.proporta.com/ted-baker-mirror-case-for-iphone-xr-leyyaa#allReviews'\n",
    "review_link='https://www.proporta.com/ted-baker-cheryia-mirror-folio-case-with-outer-card-slot-for-iphone-8-7-6-hedgerow#allReviews'\n",
    "response = get(review_link)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "reviews = soup.find_all('li', itemtype='http://schema.org/Review')\n",
    "if len(reviews) == 0:\n",
    "    no_annotation += 1\n",
    "    pass\n",
    "else:\n",
    "    for review in reviews:\n",
    "        reviewBody = review.find('p', itemprop='reviewBody')\n",
    "        for word in reviewBody:\n",
    "            neu = review.find('meta', itemprop='datePublished')\n",
    "            print(neu)\n",
    "        posted = review.find('meta', itemprop='datePublished').text\n",
    "        substring = f\"\\n {posted}$\"\n",
    "        # print(reviewBody)\n",
    "        # ratingValue = data['review']['reviewRating']['ratingValue']\n",
    "        # bestRating = data['review']['reviewRating']['bestRating']\n",
    "        # worstRating = data['review']['reviewRating']['worstRating']\n",
    "        # reviewRating = \"already included\"\n",
    "        # print(reviewBody)\n",
    "\n",
    "# //*[@id=\"reviewContainer\"]/li[1]/p/text()[2]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data = json.loads(\"\".join(soup.find(\"script\", {\"type\": \"application/ld+json\"}).contents),strict=False)\n",
    "# # print(data)\n",
    "# try:\n",
    "#     reviewBody = data['review']['reviewBody']\n",
    "#     try:\n",
    "#         ratingValue = data['review']['reviewRating']['ratingValue']\n",
    "#         bestRating = data['review']['reviewRating']['bestRating']\n",
    "#         worstRating = data['review']['reviewRating']['worstRating']\n",
    "#         reviewRating = \"already included\"\n",
    "#     except:\n",
    "#         no_rating += 1\n",
    "# except:\n",
    "#     print('no_annotation')\n",
    "\n",
    " # response = get(url)\n",
    "    # soup = BeautifulSoup(response.text, 'lxml')\n",
    "    # left_products = soup.find_all('section', class_='col-3 searchItem product left')\n",
    "    # products = soup.find_all('section', class_='col-3 searchItem product')\n",
    "    # for prod in products:\n",
    "    #     links.append(prod.a['href'])\n",
    "    # for prod in left_products:\n",
    "    #     links.append(prod.a['href'])\n",
    "\n",
    "# review = soup.find_all('div', itemtype='http://schema.org/Review')\n",
    "# if len(review) == 0:\n",
    "#     pass\n",
    "# else:\n",
    "#     node = generateNode(31)\n",
    "#     url = review_link\n",
    "#\n",
    "\n",
    "# soup.find_all('div', class_='article-card__content')\n",
    "# if review_link in current_reviews:\n",
    "#     print('already in')\n",
    "#     pass\n",
    "# else:\n",
    "#     response = get(review_link)\n",
    "#     if response.status_code != 200:\n",
    "#         problem_count += 1\n",
    "#         # print(review_link)\n",
    "#     else:\n",
    "#         review_soup = BeautifulSoup(response.text, 'lxml')\n",
    "#         # print(review_soup)\n",
    "#         node = generateNode(31)\n",
    "#         url = review_link\n",
    "#         reviewBody = \"\"\n",
    "#         for i in review_soup.find_all('div', itemprop='reviewBody'):\n",
    "#             for j in i.find_all('p'):\n",
    "#                 reviewBody = reviewBody + j.getText()\n",
    "#\n",
    "#         print('node:' + node)\n",
    "#         print('url: '+ review_link)\n",
    "#         print('reviewBody: ' + reviewBody)\n",
    "#         print('worstRating: ' + worstRating)\n",
    "#         print('bestRating: ' + bestRating)\n",
    "#         print('ratingValue: ' + ratingValue)\n",
    "#\n",
    "#         c.execute(f\"INSERT OR IGNORE INTO {db_name} (NODE, URL, REVIEWBODY, RATING, REVIEWRATING, BESTRATING, WORSTRATING) VALUES (?,?,?,?,?,?,?);\",(node,review_link,reviewBody,str(reviewRating),ratingValue,bestRating,worstRating))\n",
    "#         conn.commit()\n",
    "\n",
    "# print(f\"Done {host} - Reviews extracted: \" + str(review_count) + \", without Rating: \" + str(no_rating) + \", problems: \" + str(problem_count))\n",
    "\n",
    "# host = 'https://www.telegraph.co.uk/'\n",
    "# url = 'https://www.telegraph.co.uk/films/reviews/page-33/'\n",
    "# soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "# movie_container = soup.find_all(\"div\", class_=\"card__content\")\n",
    "# # print(movie_container)\n",
    "# for link in movie_container:\n",
    "#     # print(link)\n",
    "#     # print(link.a['href'])\n",
    "#     review_link = host + link.a['href']\n",
    "#     # if not \"movie-reviews\" in review_link:\n",
    "#     #     pass\n",
    "#     # else:\n",
    "#     print(review_link)\n",
    "\n",
    "#     # print(link.get('href'))\n",
    "#     if review_link is not None:\n",
    "#         if review_link.endswith('html'):\n",
    "#             review_soup = BeautifulSoup(get(review_link).text, 'lxml')\n",
    "#             review_html = review_soup.find(\"div\", itemtype=\"http://schema.org/Review\")\n",
    "#             # print(review_html)\n",
    "#             reviewBody = \"\"\n",
    "#             if review_html is None:\n",
    "#                 print(\"Kein Review Annotation\")\n",
    "#                 no_annotation += 1\n",
    "#             else:\n",
    "#                 reviewBody_html = review_html.find_all(\"div\", class_=\"reviewtext\")\n",
    "#                 reviewRating = review_soup.find(\"div\", itemtype=\"http://schema.org/Rating\")\n",
    "#                 for item in reviewBody_html:\n",
    "#                     reviewBody += item.p.text\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "# Snippets\n",
    "#\n",
    "# for character in string.ascii_lowercase + '0':\n",
    "#     url = f'https://deepfocusreview.com/reviews/?id={character}'\n",
    "#     response = get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'lxml')\n",
    "#     for entry in soup.find_all('ol', id='reviewalpha-list'):\n",
    "#         for link in entry.find_all('li'):\n",
    "#             # print(link.a['href'])\n",
    "#             review_count += 1\n",
    "\n",
    "# def generateNode(length):\n",
    "#     letters_and_digits = string.ascii_letters +  string.digits\n",
    "#     result_str = ''.join((random.choice(letters_and_digits) for i in range(length)))\n",
    "#     node = \"_:znode\" + result_str\n",
    "#     return node\n",
    "\n",
    "    # node = generateNode(31)\n",
    "\n",
    "# for page in range(1, 414):\n",
    "#     url = f'https://www.rollingstone.com/movies/movie-reviews/page/{page}/'\n",
    "\n",
    "# review_soup = BeautifulSoup(get(review_link).text, 'lxml')\n",
    "# review_html = review_soup.find(\"div\", itemtype=\"http://schema.org/Review\")\n",
    "# review_html = review_soup.find(id=\"pmc-movie-review-snippet\")\n",
    "\n",
    "# response = get(review_link, headers={'User-Agent': 'Custom'})\n",
    "# if response.status_code == 404:\n",
    "#     fail_lst.append(review_link)\n",
    "\n",
    "# for item in review_html:\n",
    "#     jsonExtract = str(item).split('\\n')[2].replace(\";\", \"\")\n",
    "#     data = json.loads(\"\".join(jsonExtract))\n",
    "\n",
    "    # reviewBody = data['description']\n",
    "    # ratingValue = str(data['reviewRating']['ratingValue'])\n",
    "    # bestRating = str(data['reviewRating']['bestRating'])\n",
    "    # worstRating = str(data['reviewRating']['worstRating'])\n",
    "    # reviewRating = \"already included\"\n",
    "\n",
    "    # reviewBody = soup.find_all(\"div\", itemprop=\"reviewBody\")[0].text\n",
    "    # ratingValue = soup.find_all(\"span\", itemprop=\"ratingValue\")[0].text\n",
    "    # worstRating = soup.find_all(\"meta\", itemprop=\"worstRating\")[0]['content']\n",
    "    # bestRating =soup.find_all(\"meta\", itemprop=\"bestRating\")[0]['content']\n",
    "\n",
    "    # ratingValue = review_soup.find('meta', itemprop='ratingValue')['content']\n",
    "    # worstRating = review_soup.find('meta', itemprop='worstRating')['content']\n",
    "    # bestRating = review_soup.find('meta', itemprop='bestRating')['content']\n",
    "    # reviewRating = \"already included\"\n",
    "\n",
    "# data = json.loads(\"\".join(review_soup.find(\"script\", type=\"application/ld+json\").contents))\n",
    "# data = json.loads(\"\".join(review_soup.find(\"script\", {\"type\": \"application/ld+json\"}).contents),strict=False)\n",
    "\n",
    "# reviewBody_html = review_html.find_all(\"div\", class_=\"reviewtext\")\n",
    "\n",
    "# reviewRating = review_soup.find(\"div\", itemtype=\"http://schema.org/Rating\")\n",
    "\n",
    "# reviewBody += item.p.text\n",
    "\n",
    "# worstRating = reviewRating.find(\"meta\", itemprop=\"worstRating\")[\"content\"]\n",
    "# bestRating = reviewRating.find(\"meta\", itemprop=\"bestRating\")[\"content\"]\n",
    "# ratingValue = reviewRating.find(\"meta\", itemprop=\"ratingValue\")[\"content\"]\n",
    "\n",
    "# print('node:' + node)\n",
    "# print('url: '+ review_link)\n",
    "# print('reviewBody: ' + reviewBody)\n",
    "# print('worstRating: ' + worstRating)\n",
    "# print('bestRating: ' + bestRating)\n",
    "# print('ratingValue: ' + ratingValue)\n",
    "\n",
    "# c.execute(f\"INSERT OR IGNORE INTO {db_name} (NODE, URL, REVIEWBODY, RATING, REVIEWRATING, BESTRATING, WORSTRATING) VALUES (?,?,?,?,?,?,?);\",(node,review_link,reviewBody,str(reviewRating),ratingValue,bestRating,worstRating))\n",
    "# conn.commit()\n",
    "\n",
    "# soup = BeautifulSoup(get(url).text, 'html.parser')\n",
    "# movie_container = soup.find_all(\"div\", class_=\"entry post clearfix\")\n",
    "# for link in movie_container[0].find_all(\"a\"):\n",
    "#     review_link = link.get('href')\n",
    "#     print(link.get('href'))\n",
    "#     if review_link is not None:\n",
    "#         if review_link.endswith('html'):\n",
    "#             if review_link in current_reviews:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 print(review_link)\n",
    "#                 manche haben schema.org/Review nicht drin\n",
    "#                 review_count += 1\n",
    "#         if review_link.endswith('html') & review_link not in current_reviews:\n",
    "#             print(review_link)\n",
    "#         else:\n",
    "#             pass\n",
    "#                 #nicht alle Einträge sind vollständig (fehlende Bewertung)\n",
    "#                 # review_count += 1\n",
    "#     else:\n",
    "#         pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}