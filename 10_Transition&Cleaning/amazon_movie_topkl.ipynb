{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## FIRST GENERAL INSIGHT\n",
      "                                                text  label\n",
      "0  This is a charming version of the classic Dick...    4.0\n",
      "1  It was good but not as emotionally moving as t...    3.0\n",
      "2  Don't get me wrong, Winkler is a wonderful cha...    3.0\n",
      "3  Henry Winkler is very good in this twist on th...    5.0\n",
      "4  This is one of the best Scrooge movies out.  H...    4.0\n",
      "######## Total: \n",
      "Amount of reviews:  1697533\n",
      "######## DESCRIPTION\n",
      "           text         label\n",
      "count   1697533  1.697533e+06\n",
      "unique  1696352           NaN\n",
      "top                       NaN\n",
      "freq         62           NaN\n",
      "mean        NaN  4.110648e+00\n",
      "std         NaN  1.197615e+00\n",
      "min         NaN  1.000000e+00\n",
      "25%         NaN  4.000000e+00\n",
      "50%         NaN  5.000000e+00\n",
      "75%         NaN  5.000000e+00\n",
      "max         NaN  5.000000e+00\n",
      "######## DATA COMPLETENESS\n",
      "Missing/Empty review text: 62\n",
      "Missing review text as percentage: 0.00% \n",
      "Missing rating information 0\n",
      "Missing rating information as percentage: 0.00%\n",
      "After removing implictly missing rating information:  1697471\n",
      "######## DUPLICATE DETECTION\n",
      "Duplicate text: 1120\n",
      "Duplicate text: 0.07%\n",
      "Duplicate text and label: 973\n",
      "Duplicate text and label from reviews without missing information: 0.06%\n",
      "After removing duplicate entries and texts:  1696351\n",
      "######## LINGUISTIC AFFILIATION\n",
      "exception: :)\n",
      "exception: ********* **** ********* *** ***** ****** ***** ****** ****** ******* ********** *********** ****** ****** *****  ***** **** **** ****** ****** *******\n",
      "exception: ........ ...... .. . .... ... ...... ..... ... .... .... ..... .. .. .. .. .. .. .. .. .. ... .. .. .. .. .. .. .. . ... .. ... .... ... ... . ..... ... ... ... ... ... .\n",
      "en    1693063\n",
      "de        758\n",
      "es        700\n",
      "af        344\n",
      "fr        227\n",
      "so        120\n",
      "ro        104\n",
      "it        100\n",
      "ca         93\n",
      "no         93\n",
      "cy         89\n",
      "pt         89\n",
      "nl         71\n",
      "da         64\n",
      "sk         63\n",
      "sl         62\n",
      "tl         44\n",
      "et         40\n",
      "vi         40\n",
      "id         35\n",
      "pl         32\n",
      "sq         28\n",
      "hr         17\n",
      "hu         14\n",
      "tr         13\n",
      "fi         12\n",
      "sv         10\n",
      "sw          8\n",
      "cs          7\n",
      "lt          5\n",
      "lv          3\n",
      "Name: LANGUAGE, dtype: int64\n",
      "After removing non-english text: 1693063\n",
      "######## OTHER HEURISTICS\n",
      "After removing from other cleaning heuristics:  1693062\n",
      "######## PREPROCESSING\n",
      "######## Web Data Specific\n",
      "removed html tags\n",
      "removed hyperlinks\n",
      "removed content between square brackets\n",
      "removed content between angle brackets\n",
      "html unescape done\n",
      "white space removal done\n",
      "language indicator removal done\n",
      "######## Text Harmonization\n",
      "contractions expansion done\n",
      "removed accented characters\n",
      "tokenization done\n",
      "316192659\n",
      "abbreviation transformation done\n",
      "number removal done\n",
      "Token Count:  314995423\n",
      "punctuation and non-ascii removal done\n",
      "Token Count:  282167885\n",
      "######## LOWERCASING STATISTICS\n",
      "Amount of All Capitals words: 4431624\n",
      "     Word  Frequency\n",
      "0     DVD     422420\n",
      "1       A     378088\n",
      "2     THE     136797\n",
      "3      TV     123630\n",
      "4       D      52377\n",
      "5       S      49237\n",
      "6       B      48065\n",
      "7      OF      46793\n",
      "8     AND      44979\n",
      "9     NOT      36877\n",
      "10      O      36874\n",
      "11   THIS      34047\n",
      "12     IS      33830\n",
      "13     IT      31232\n",
      "14    VHS      29854\n",
      "15     TO      29511\n",
      "16      X      28094\n",
      "17     II      27472\n",
      "18      C      24593\n",
      "19      R      24427\n",
      "20      T      24392\n",
      "21     US      24237\n",
      "22     IN      23070\n",
      "23    CGI      22192\n",
      "24      J      22087\n",
      "25     HD      19642\n",
      "26  MOVIE      19619\n",
      "27     OK      18993\n",
      "28      L      17701\n",
      "29      H      17293\n",
      "30      E      17282\n",
      "31      M      17160\n",
      "32    ALL      16637\n",
      "33    YOU      15953\n",
      "34    WWE      15666\n",
      "35   THAT      15448\n",
      "36   LOVE      14708\n",
      "37      G      14677\n",
      "38  GREAT      14594\n",
      "39    WAS      14521\n",
      "40      P      14479\n",
      "41    FOR      13924\n",
      "42      K      13901\n",
      "43      F      13152\n",
      "44    BUT      13144\n",
      "45   VERY      12937\n",
      "46      W      12775\n",
      "47     ON      12669\n",
      "48      V      12649\n",
      "49    BBC      12309\n",
      "lowercasing done\n",
      "stopword removal done\n",
      "Token Count:  150036351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\pandas\\core\\strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from Scripts import loading as dl, profiling as pf, cleaning as cl, preprocessing as prep\n",
    "\n",
    "\n",
    "input_link = '../Data/reviews_Movies_and_TV_5.json.gz'\n",
    "df = dl.load_amazon_full(input_link)\n",
    "\n",
    "\n",
    "print('######## FIRST GENERAL INSIGHT')\n",
    "print(df.head())\n",
    "pf.get_review_count(df)\n",
    "pf.get_descr(df)\n",
    "\n",
    "\n",
    "print('######## DATA COMPLETENESS')\n",
    "pf.get_missing_text(df)\n",
    "pf.get_missing_label(df)\n",
    "df = cl.proceed_data_completion(df)\n",
    "\n",
    "\n",
    "print('######## DUPLICATE DETECTION')\n",
    "pf.get_duplicates(df)\n",
    "df = cl.drop_duplicates(df)\n",
    "\n",
    "\n",
    "print('######## LINGUISTIC AFFILIATION')\n",
    "df = cl.remove_non_english(df)\n",
    "# pf.show_lang_dist(df, 'amazon_movie_lang_non_eng_dist', 'non-English Language Distribution (Amazon Movies & TV)', 0)\n",
    "# pf.show_lang_dist(df, 'amazon_movie_lang_all_dist', 'Language Distribution (Amazon Movies & TV)', 1)\n",
    "\n",
    "\n",
    "print('######## OTHER HEURISTICS')\n",
    "df = df[~df.text.str.contains(r'^&#((15|16|20)[0-9]{2,3});*')]\n",
    "print('After removing from other cleaning heuristics: ', len(df))\n",
    "\n",
    "\n",
    "print('######## PREPROCESSING')\n",
    "print('######## Web Data Specific')\n",
    "df = prep.remove_html(df)\n",
    "df = prep.remove_hyperlinks(df)\n",
    "df = prep.remove_between_square_brackets(df)\n",
    "df = prep.remove_between_angle_brackets(df)\n",
    "df = prep.unescape(df)\n",
    "df = prep.remove_whitespaces(df)\n",
    "df = prep.remove_lang_ind(df)\n",
    "\n",
    "print('######## Text Harmonization')\n",
    "df = prep.replace_contractions(df)\n",
    "df = prep.remove_accented_chars(df)\n",
    "df = prep.to_token(df)\n",
    "total_token_count = pf.get_total_token_count(df)\n",
    "print(total_token_count)\n",
    "df = prep.transform_abbr(df)\n",
    "df = prep.remove_numbers(df)\n",
    "df = prep.remove_punct_and_nonascii(df)\n",
    "df = prep.to_lower(df)\n",
    "df = prep.remove_stopwords(df)\n",
    "df = prep.get_pos(df)\n",
    "\n",
    "print('######## Text Canonicalization')\n",
    "df = prep.stem(df)\n",
    "\n",
    "pf.get_prep_summary(df, total_token_count)\n",
    "\n",
    "df = prep.detokenize(df)\n",
    "\n",
    "print('######## DATA COMPLETION AFTER PREPROCESSING')\n",
    "total_prep = len(df)\n",
    "df_empty = df[df.text_prep=='']\n",
    "print(\"Empty preprocessed text:\", len(df_empty))\n",
    "print(\"Duplicate preprocessed text: {:.2%}\".format(len(df_empty) / total_prep))\n",
    "df = df[df.text_prep!='']\n",
    "print(\"After removing empty preprocessed texts: \", len(df))\n",
    "\n",
    "print('######## DEDUPLICATION AFTER PREPROCESSING')\n",
    "df_dup = df[df.duplicated(subset=['text_prep'], keep='last')]\n",
    "print(\"Duplicate preprocessed text:\", len(df_dup))\n",
    "print(\"Duplicate preprocessed text: {:.2%}\".format(len(df_dup) / total_prep))\n",
    "df = df.drop_duplicates(subset=['text_prep'], keep='last')\n",
    "print(\"After removing duplicate preprocessed texts: \", len(df))\n",
    "\n",
    "\n",
    "print('######### LAST CHECK')\n",
    "print(df.head())\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "\n",
    "print('######## STORING')\n",
    "df = df[['text','label', 'text_prep', 'token_count', 'upper', 'pos']]\n",
    "df.columns=['text', 'label', 'text_prep', 'token_count', 'upper', 'pos']\n",
    "df.to_pickle('../Data/amazon_movie.pkl')\n",
    "print('to pickle done')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}