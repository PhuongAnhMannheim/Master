{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 reviews per class from ../Data/amazon_phone.pkl loaded\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "LogisticRegression\n",
      "{'clf__C': 0.1, 'clf__multi_class': 'ovr', 'clf__penalty': 'l2', 'clf__solver': 'newton-cg', 'vect__ngram_range': (1, 3)}\n",
      "0.23333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:    8.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "amazon_link = '../Data/amazon_phone.pkl'\n",
    "\n",
    "# ToDo: reference to module\n",
    "# from Scripts import loading as dl\n",
    "# df = dl.load_sampled(amazon_link, 5000)\n",
    "def load_sampled(link, per_class):\n",
    "    df = pd.read_pickle(link)\n",
    "    df_1 = df[df['label'] == 1.0].values.tolist()\n",
    "    df_2 = df[df['label'] == 2.0].values.tolist()\n",
    "    df_3 = df[df['label'] == 3.0].values.tolist()\n",
    "    df_4 = df[df['label'] == 4.0].values.tolist()\n",
    "    df_5 = df[df['label'] == 5.0].values.tolist()\n",
    "\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf1 = random.sample(df_1, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf1 = random.choices(df_1, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf2 = random.sample(df_2, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf2 = random.choices(df_2, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf3 = random.sample(df_3, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf3 = random.choices(df_3, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf4 = random.sample(df_4, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf4 = random.choices(df_4, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf5 = random.sample(df_5, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf5 = random.choices(df_5, k=per_class)\n",
    "    adf11 = pd.DataFrame(adf1)\n",
    "    adf12 = pd.DataFrame(adf2)\n",
    "    adf13 = pd.DataFrame(adf3)\n",
    "    adf14 = pd.DataFrame(adf4)\n",
    "    adf15 = pd.DataFrame(adf5)\n",
    "    df_all = pd.concat([adf11, adf12, adf13, adf14, adf15], ignore_index=True)\n",
    "    df_all = df_all[[2, 1]]\n",
    "    df_all.columns = ['text_prep', 'label']\n",
    "    print(f'{per_class} reviews per class from {link} loaded')\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df = load_sampled(amazon_link, 5000)\n",
    "df = df.sample(frac=0.001)\n",
    "target = df.label\n",
    "text = df.text_prep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.3, random_state=123)\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "param_grid = [{'vect__ngram_range': [(1, 3)],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [0.1, 1.0, 10.0],\n",
    "               'clf__solver': ['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "               'clf__multi_class': ['ovr', 'multinomial']\n",
    "               }]\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=123))])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring='f1_macro', cv=5, verbose=1, n_jobs=-1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)\n",
    "print('LogisticRegression')\n",
    "print(gs_lr_tfidf.best_params_)\n",
    "print(gs_lr_tfidf.best_score_)\n",
    "\n",
    "\n",
    "# param_grid = [{'vect__ngram_range': [(1, 3)],\n",
    "#                'clf__alpha': [0.1, 1.0, 10.0],\n",
    "#                'clf__fit_prior': [True, False]\n",
    "#                }]\n",
    "# nb_tfidf = Pipeline([('vect', tfidf),\n",
    "#                      ('clf', MultinomialNB())])\n",
    "# gs_nb_tfidf = GridSearchCV(nb_tfidf, param_grid, scoring='f1_macro', cv=5, verbose=1, n_jobs=-1)\n",
    "# gs_nb_tfidf.fit(X_train, y_train)\n",
    "# print('MultinomialNB')\n",
    "# print(gs_nb_tfidf.best_params_)\n",
    "# print(gs_nb_tfidf.best_score_)\n",
    "\n",
    "\n",
    "# param_grid = [{'vect__ngram_range': [(1, 3)],\n",
    "#                'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#                'clf__C': [0.1, 1.0, 10.0],\n",
    "#                'clf__gamma': ['auto', 'scale']\n",
    "#                }]\n",
    "# svr_tfidf = Pipeline([('vect', tfidf),\n",
    "#                      ('clf', SVR())])\n",
    "# gs_svr_tfidf = GridSearchCV(svr_tfidf, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "# gs_svr_tfidf.fit(X_train, y_train)\n",
    "# print('SVR')\n",
    "# print(gs_svr_tfidf.best_params_)\n",
    "# print(gs_svr_tfidf.best_score_)\n",
    "\n",
    "\n",
    "# param_grid = [{'vect__ngram_range': [(1, 3)],\n",
    "#                'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#                'clf__C': [0.1, 1.0, 10.0],\n",
    "#                'clf__gamma': ['auto', 'scale'],\n",
    "#                'clf__decision_function_shape': ['ovo', 'ovr']\n",
    "#                }]\n",
    "# svc_tfidf = Pipeline([('vect', tfidf),\n",
    "#                      ('clf', SVC())])\n",
    "# gs_svc_tfidf = GridSearchCV(svc_tfidf, param_grid, scoring='f1_macro', cv=5, verbose=3, n_jobs=-1)\n",
    "# gs_svc_tfidf.fit(X_train, y_train)\n",
    "# print('SVC')\n",
    "# print(gs_svc_tfidf.best_params_)\n",
    "# print(gs_svc_tfidf.best_score_)\n",
    "\n",
    "\n",
    "# param_grid = [{'vect__ngram_range': [(1, 3)],\n",
    "#                'clf__penalty': ['l1', 'l2'],\n",
    "#                'clf__alpha': [0.1, 0.01, 0.001, 0.0001],\n",
    "#                'clf__max_iter': [500, 1000, 10000]\n",
    "#                }]\n",
    "# sdg_tfidf = Pipeline([('vect', tfidf),\n",
    "#                      ('clf', SGDClassifier(loss='hinge', random_state=123))])\n",
    "# gs_sdg_tfidf = GridSearchCV(sdg_tfidf, param_grid, scoring='f1_macro', cv=5, verbose=1, n_jobs=-1)\n",
    "# gs_sdg_tfidf.fit(X_train, y_train)\n",
    "# print('SGDClassifier')\n",
    "# print(gs_sdg_tfidf.best_params_)\n",
    "# print(gs_sdg_tfidf.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}