{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 reviews per class from ../Data/amazon_phone.pkl loaded\n",
      "3.0    55\n",
      "1.0    52\n",
      "4.0    51\n",
      "2.0    49\n",
      "5.0    43\n",
      "Name: label, dtype: int64\n",
      "                                               text_prep  label\n",
      "14051  case good job but not look good seen pictur wh...    3.0\n",
      "7470   work well but design heavi fall wall outlet ma...    2.0\n",
      "2307   let us say leav phone hous go patio garag want...    1.0\n",
      "20742  great extern batteri anyon want carri charg mi...    5.0\n",
      "21189  sabrent port famili size usb wall charger exac...    5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "amazon_link = '../Data/amazon_phone.pkl'\n",
    "\n",
    "# ToDo: reference to module\n",
    "# from Scripts import loading as dl\n",
    "# df = dl.load_sampled(amazon_link, 5000)\n",
    "def load_sampled(link, per_class):\n",
    "    df = pd.read_pickle(link)\n",
    "    df_1 = df[df['label'] == 1.0].values.tolist()\n",
    "    df_2 = df[df['label'] == 2.0].values.tolist()\n",
    "    df_3 = df[df['label'] == 3.0].values.tolist()\n",
    "    df_4 = df[df['label'] == 4.0].values.tolist()\n",
    "    df_5 = df[df['label'] == 5.0].values.tolist()\n",
    "\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf1 = random.sample(df_1, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf1 = random.choices(df_1, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf2 = random.sample(df_2, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf2 = random.choices(df_2, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf3 = random.sample(df_3, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf3 = random.choices(df_3, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf4 = random.sample(df_4, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf4 = random.choices(df_4, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf5 = random.sample(df_5, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf5 = random.choices(df_5, k=per_class)\n",
    "    adf11 = pd.DataFrame(adf1)\n",
    "    adf12 = pd.DataFrame(adf2)\n",
    "    adf13 = pd.DataFrame(adf3)\n",
    "    adf14 = pd.DataFrame(adf4)\n",
    "    adf15 = pd.DataFrame(adf5)\n",
    "    df_all = pd.concat([adf11, adf12, adf13, adf14, adf15], ignore_index=True)\n",
    "    df_all = df_all[[2, 1]]\n",
    "    df_all.columns = ['text_prep', 'label']\n",
    "    print(f'{per_class} reviews per class from {link} loaded')\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df = load_sampled(amazon_link, 5000)\n",
    "target = df.label\n",
    "text = df.text_prep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.3, random_state=123)\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [0.1, 1.0, 10.0],\n",
    "               'clf__multi_class': ['ovr', 'multinomial']\n",
    "               }]\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=123))])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring='f1_macro', cv=5, verbose=1, n_jobs=-1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)\n",
    "print('LogisticRegression')\n",
    "print(gs_lr_tfidf.best_params_)\n",
    "print(gs_lr_tfidf.best_score_)\n",
    "\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'clf__alpha': [0.1, 1.0, 10.0],\n",
    "               'clf__fit_prior': [True, False]\n",
    "               }]\n",
    "nb_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', MultinomialNB())])\n",
    "gs_nb_tfidf = GridSearchCV(nb_tfidf, param_grid, scoring='f1_macro', cv=5, verbose=1, n_jobs=-1)\n",
    "gs_nb_tfidf.fit(X_train, y_train)\n",
    "print('MultinomialNB')\n",
    "print(gs_nb_tfidf.best_params_)\n",
    "print(gs_nb_tfidf.best_score_)\n",
    "\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "               'clf__C': [0.1, 1.0, 10.0],\n",
    "               'clf__gamma': ['auto', 'scale']\n",
    "               }]\n",
    "svr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', SVR())])\n",
    "gs_svr_tfidf = GridSearchCV(svr_tfidf, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "gs_svr_tfidf.fit(X_train, y_train)\n",
    "print('SVR')\n",
    "print(gs_svr_tfidf.best_params_)\n",
    "print(gs_svr_tfidf.best_score_)\n",
    "\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "               'clf__C': [0.1, 1.0, 10.0],\n",
    "               'clf__gamma': ['auto', 'scale'],\n",
    "               'clf__decision_function_shape': ['ovo', 'ovr']\n",
    "               }]\n",
    "svc_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', SVC())])\n",
    "gs_svc_tfidf = GridSearchCV(svc_tfidf, param_grid, scoring='f1_macro', cv=5, verbose=3, n_jobs=-1)\n",
    "gs_svc_tfidf.fit(X_train, y_train)\n",
    "print('SVC')\n",
    "print(gs_svc_tfidf.best_params_)\n",
    "print(gs_svc_tfidf.best_score_)\n",
    "\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__alpha': [0.1, 0.01, 0.001, 0.0001],\n",
    "               'clf__max_iter': [500, 1000, 10000]\n",
    "               }]\n",
    "sdg_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', SGDClassifier(loss='hinge', random_state=123))])\n",
    "gs_sdg_tfidf = GridSearchCV(sdg_tfidf, param_grid, scoring='f1_macro', cv=5, verbose=1, n_jobs=-1)\n",
    "gs_sdg_tfidf.fit(X_train, y_train)\n",
    "print('SGDClassifier')\n",
    "print(gs_sdg_tfidf.best_params_)\n",
    "print(gs_sdg_tfidf.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}