{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 reviews per class from ../Data/amazon_phone.pkl loaded\n",
      "3.0    54\n",
      "5.0    54\n",
      "4.0    53\n",
      "1.0    45\n",
      "2.0    44\n",
      "Name: label, dtype: int64\n",
      "Fitting 5 folds for each of 85 candidates, totalling 425 fits\n",
      "best parameters\n",
      "{'vect': CountVectorizer(max_df=0.75, min_df=5), 'vect__max_df': 0.75, 'vect__min_df': 5}\n",
      "best score\n",
      "0.35961567843920783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 410 out of 425 | elapsed:    4.7s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 425 out of 425 | elapsed:    4.8s finished\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   vect__binary  vect__max_df  vect__min_df  \\\n0          True           0.5             1   \n1          True           0.5             2   \n2          True           0.5             3   \n3          True           0.5             5   \n4          True           0.5            10   \n..          ...           ...           ...   \n80          NaN           1.0             1   \n81          NaN           1.0             2   \n82          NaN           1.0             3   \n83          NaN           1.0             5   \n84          NaN           1.0            10   \n\n                                      vect  f1_macro  \n0                                      NaN  0.319691  \n1                                      NaN  0.305820  \n2                                      NaN  0.269140  \n3                                      NaN  0.277963  \n4                                      NaN  0.250416  \n..                                     ...       ...  \n80  CountVectorizer(max_df=0.75, min_df=5)  0.346092  \n81  CountVectorizer(max_df=0.75, min_df=5)  0.341126  \n82  CountVectorizer(max_df=0.75, min_df=5)  0.352759  \n83  CountVectorizer(max_df=0.75, min_df=5)  0.359616  \n84  CountVectorizer(max_df=0.75, min_df=5)  0.338016  \n\n[85 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vect__binary</th>\n      <th>vect__max_df</th>\n      <th>vect__min_df</th>\n      <th>vect</th>\n      <th>f1_macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>True</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.319691</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>0.5</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>0.305820</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>0.5</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.269140</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>0.5</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>0.277963</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>True</td>\n      <td>0.5</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.250416</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>CountVectorizer(max_df=0.75, min_df=5)</td>\n      <td>0.346092</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>CountVectorizer(max_df=0.75, min_df=5)</td>\n      <td>0.341126</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>CountVectorizer(max_df=0.75, min_df=5)</td>\n      <td>0.352759</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>CountVectorizer(max_df=0.75, min_df=5)</td>\n      <td>0.359616</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>CountVectorizer(max_df=0.75, min_df=5)</td>\n      <td>0.338016</td>\n    </tr>\n  </tbody>\n</table>\n<p>85 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "amazon_link = '../Data/amazon_phone.pkl'\n",
    "\n",
    "# ToDo: reference to module\n",
    "# from Scripts import loading as dl\n",
    "# df = dl.load_sampled(amazon_link, 5000)\n",
    "def load_sampled(link, per_class):\n",
    "    df = pd.read_pickle(link)\n",
    "    df_1 = df[df['label'] == 1.0].values.tolist()\n",
    "    df_2 = df[df['label'] == 2.0].values.tolist()\n",
    "    df_3 = df[df['label'] == 3.0].values.tolist()\n",
    "    df_4 = df[df['label'] == 4.0].values.tolist()\n",
    "    df_5 = df[df['label'] == 5.0].values.tolist()\n",
    "\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf1 = random.sample(df_1, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf1 = random.choices(df_1, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf2 = random.sample(df_2, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf2 = random.choices(df_2, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf3 = random.sample(df_3, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf3 = random.choices(df_3, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf4 = random.sample(df_4, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf4 = random.choices(df_4, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf5 = random.sample(df_5, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf5 = random.choices(df_5, k=per_class)\n",
    "    adf11 = pd.DataFrame(adf1)\n",
    "    adf12 = pd.DataFrame(adf2)\n",
    "    adf13 = pd.DataFrame(adf3)\n",
    "    adf14 = pd.DataFrame(adf4)\n",
    "    adf15 = pd.DataFrame(adf5)\n",
    "    df_all = pd.concat([adf11, adf12, adf13, adf14, adf15], ignore_index=True)\n",
    "    df_all = df_all[[2, 1]]\n",
    "    df_all.columns = ['text_prep', 'label']\n",
    "    print(f'{per_class} reviews per class from {link} loaded')\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df = load_sampled(amazon_link, 5000)\n",
    "df = df.sample(frac=0.01, random_state=123)\n",
    "print(df.label.value_counts())\n",
    "target = df.label\n",
    "text = df.text_prep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.3, random_state=None)\n",
    "\n",
    "count = TfidfVectorizer()\n",
    "param_grid = [{\n",
    "    'vect__max_df': [0.5, 0.75, 0.8, 0.9, 1.0],\n",
    "    'vect__min_df': [1, 2, 3, 5, 10, 20],\n",
    "    'vect__binary': [True, False]\n",
    "}, {\n",
    "    'vect': [CountVectorizer(),],\n",
    "    'vect__max_df': [0.5, 0.75, 0.8, 0.9, 1.0],\n",
    "    'vect__min_df': [1, 2, 3, 5, 10],\n",
    "\n",
    "}]\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=False, random_state=123)\n",
    "ml_features = Pipeline([('vect', count),\n",
    "                        ('clf', LogisticRegression(C=10.0, multi_class='multinomial', penalty='l2', solver='saga', random_state=123))])\n",
    "\n",
    "gs_ml_features = GridSearchCV(ml_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_ml_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_ml_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_ml_features.best_score_)\n",
    "\n",
    "\n",
    "pd.concat([pd.DataFrame(gs_ml_features.cv_results_[\"params\"]),pd.DataFrame(gs_ml_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}