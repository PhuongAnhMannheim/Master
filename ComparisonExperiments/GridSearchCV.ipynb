{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Scripts import loading as dl, preprocessing as prep\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest,f_regression, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "movie_link = '../Data/amazon_movie.pkl'\n",
    "df = dl.load_sampled(movie_link, 10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label\n0  I did not learn after the first movie.  I boug...    1.0\n1  I won't review the movie because this has alre...    1.0\n2  never explained anything and the ending was th...    1.0\n3  pathetic acting and unrealistic jujitsu fight ...    1.0\n4  Incredible (as in unbelievable) that three suc...    1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I did not learn after the first movie.  I boug...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I won't review the movie because this has alre...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>never explained anything and the ending was th...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pathetic acting and unrealistic jujitsu fight ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Incredible (as in unbelievable) that three suc...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "text = prep.preprocess_reviews(df.text)\n",
    "target = df.label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.25,random_state=7, stratify=df.label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Training target statistics: {}'.format(Counter(y_train), sorted(y_train)))\n",
    "print('Testing target statistics: {}'.format(Counter(y_test), sorted(y_test)))\n",
    "vectorizer = TfidfVectorizer(min_df=5,max_df=0.9, ngram_range=(1,3))\n",
    "train_vectorized = vectorizer.fit_transform(X_train)\n",
    "test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "vectorizer_fs = SelectKBest(score_func=f_classif, k=1000)\n",
    "fs_train_vectorized = vectorizer_fs.fit_transform(train_vectorized,y_train)\n",
    "fs_test_vectorized = vectorizer_fs.transform(test_vectorized)\n",
    "clf = LogisticRegression(C=1.0, dual=False, fit_intercept=True, random_state=0, solver='lbfgs', intercept_scaling=1, max_iter=100, multi_class='multinomial', class_weight='balanced')\n",
    "clf.fit(fs_train_vectorized, y_train)\n",
    "y_pred = clf.predict(fs_test_vectorized)\n",
    "accuracy = str(metrics.accuracy_score(y_test, y_pred))\n",
    "precision = str(metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "recall = str(metrics.recall_score(y_test, y_pred))\n",
    "f1 = str(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Accuracy:\" + accuracy)\n",
    "print(\"Precision:\" + precision)\n",
    "print(\"F1:\" + f1)\n",
    "print(pd.crosstab(y_test, y_pred))\n",
    "\n",
    "# Visualization of Confusion Matrix and saving\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "title = f\"Confusion matrix 75_25)\"\n",
    "disp = plot_confusion_matrix(clf, fs_test_vectorized, y_test,\n",
    "                             display_labels=[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                             cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "\n",
    "title_norm = title + \"_normalize\"\n",
    "disp_norm = plot_confusion_matrix(clf, fs_test_vectorized, y_test,\n",
    "                             display_labels=[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true')\n",
    "disp_norm.ax_.set_title(title_norm)\n",
    "plt.show()\n",
    "\n",
    "# Tfidf\n",
    "# Accuracy:0.5044\n",
    "# Precision:0.49877848211061393\n",
    "# F1:0.5005075581374712\n",
    "\n",
    "# Count\n",
    "# Accuracy:0.49352\n",
    "# Precision:0.48421926835444573\n",
    "# F1:0.4849920759957114"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 56.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 97.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 142.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed: 210.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed: 299.4min\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     ('vect', TfidfVectorizer()),\n",
    "#     ('select',SelectKBest()),\n",
    "#     ('clf',LogisticRegression(fit_intercept=True, dual=False, random_state=123, verbose=3))\n",
    "# ])\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf',LogisticRegression())\n",
    "])\n",
    "# parameters = [{\n",
    "#     'vect__max_df': (0.5, 0.75, 0.8, 0.9, 1.0),\n",
    "#     'vect__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "#     'vect__min_df': (2,3,4,5),\n",
    "#     'vect__norm': ('l1','l2'),\n",
    "#     'vect__sublinear_tf': (True, False),\n",
    "#     'select__score_func': (f_classif, f_regression),\n",
    "#     'select__k': (500,1000,1500,2000,2500,3000,3500,4000,4500,5000),\n",
    "#     'clf__C': (np.logspace(-4,4,20),1.0),\n",
    "#     'clf__solver': ('liblinear', 'lbfgs', 'saga'),\n",
    "#     'clf__max_iter': (100,200,500,1000),\n",
    "#     'clf__class_weight': (None, 'balanced'),\n",
    "#     'clf__multi_class': ('ovr', 'multinomial')\n",
    "# },{\n",
    "#     'vect': (CountVectorizer(),),\n",
    "#     'vect__max_df': (0.5, 0.75, 0.8, 0.9, 1.0),\n",
    "#     'vect__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "#     'vect__min_df': (2,3,4,5),\n",
    "#     'vect__norm': ('l1','l2'),\n",
    "#     'vect__sublinear_tf': (True, False),\n",
    "#     'select__score_func': (f_classif, f_regression),\n",
    "#     'select__k': (500,1000,1500,2000,2500,3000,3500,4000,4500,5000),\n",
    "#     'clf__C': (np.logspace(-4,4,20),1.0),\n",
    "#     'clf__solver': ('liblinear', 'lbfgs', 'saga'),\n",
    "#     'clf__max_iter': (100,200,500,1000),\n",
    "#     'clf__class_weight': (None, 'balanced'),\n",
    "#     'clf__multi_class': ('ovr', 'multinomial')\n",
    "# }]\n",
    "parameters = [{\n",
    "    'vect__max_df': (0.5, 0.75, 0.8, 0.9, 1.0),\n",
    "    'vect__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "    'vect__min_df': (2,3,4,5),\n",
    "    'vect__norm': ('l1','l2'),\n",
    "    'vect__sublinear_tf': (True, False),\n",
    "    'clf__multi_class': ('ovr', 'multinomial')\n",
    "},{\n",
    "    'vect': (CountVectorizer(),),\n",
    "    'vect__max_df': (0.5, 0.75, 0.8, 0.9, 1.0),\n",
    "    'vect__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "    'vect__min_df': (2,3,4,5),\n",
    "    'vect__norm': ('l1','l2'),\n",
    "    'vect__sublinear_tf': (True, False),\n",
    "    'clf__multi_class': ('ovr', 'multinomial')\n",
    "}]\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = parameters,\n",
    "    cv = 5,\n",
    "    n_jobs = -1,\n",
    "    verbose = 3\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'scorer_'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-0f441c457743>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mgrid_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscore\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mscore\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    451\u001B[0m         \"\"\"\n\u001B[0;32m    452\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_is_fitted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'score'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 453\u001B[1;33m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscorer_\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    454\u001B[0m             raise ValueError(\"No score function explicitly defined, \"\n\u001B[0;32m    455\u001B[0m                              \u001B[1;34m\"and the estimator doesn't provide one %s\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'GridSearchCV' object has no attribute 'scorer_'"
     ]
    }
   ],
   "source": [
    "grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}