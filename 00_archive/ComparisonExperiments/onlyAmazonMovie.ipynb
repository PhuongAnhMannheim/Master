{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, json, random, pandas as pd\n",
    "from Scripts import preprocessing as prep, cleaning as clean, loading as dl\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_classif, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "amazon_input = '../Data/reviews_Movies_and_TV_5.json.gz'\n",
    "data = []\n",
    "with gzip.open(amazon_input) as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "df = pd.DataFrame.from_dict(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "1697533"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ama_df = df[['reviewText', 'overall']]\n",
    "len(ama_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deleting duplicate entries:  1697533\n",
      "After deleting duplicate entries:  1697533\n"
     ]
    }
   ],
   "source": [
    "ama_df = clean.remove_duplicates(ama_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-27-6df52b3f6623>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mama_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "ama_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ama_df = clean.remove_dup_text(ama_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WITH PREPROCESSING => IMPROVING PERFORMANCE\n",
    "clean_text = prep.preprocess_reviews(ama_df['reviewText'])\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "text_count = vectorizer.fit_transform(clean_text)\n",
    "# ros = RandomOverSampler(random_state=777)\n",
    "undersampler = RandomUnderSampler(random_state=None)\n",
    "text_count_res, target_res = undersampler.fit_sample(text_count, ama_df['overall'])\n",
    "print(\"finished balancing\")\n",
    "clf = MultinomialNB()\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_count_res, target_res, test_size=0.25, random_state=109)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = str(metrics.accuracy_score(y_test, y_pred))\n",
    "precision = str(metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "f1 = str(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(f1)\n",
    "print(metrics.classification_report(y_test, y_pred, labels = [1.0, 2.0, 3.0, 4.0, 5.0]))\n",
    "disp_norm = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                      display_labels=[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                                      cmap=plt.cm.Blues,\n",
    "                                      normalize='true')\n",
    "vocab_3 = vectorizer.get_feature_names()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training target statistics: Counter({5.0: 18577, 4.0: 4243, 3.0: 993, 1.0: 246, 2.0: 243})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1 = ama_df[ama_df['overall']==1.0].values.tolist()\n",
    "df_2 = ama_df[ama_df['overall']==2.0].values.tolist()\n",
    "df_3 = ama_df[ama_df['overall']==3.0].values.tolist()\n",
    "df_4 = ama_df[ama_df['overall']==4.0].values.tolist()\n",
    "df_5 = ama_df[ama_df['overall']==5.0].values.tolist()\n",
    "df1 = random.sample(df_1, 8000)\n",
    "df2 = random.sample(df_2, 8000)\n",
    "df3 = random.sample(df_3, 8000)\n",
    "df4 = random.sample(df_4, 8000)\n",
    "df5 = random.sample(df_5, 8000)\n",
    "df11 = pd.DataFrame(df1[1:], columns=['reviewText', 'overall'])\n",
    "df12 = pd.DataFrame(df2[1:], columns=['reviewText', 'overall'])\n",
    "df13 = pd.DataFrame(df3[1:], columns=['reviewText', 'overall'])\n",
    "df14 = pd.DataFrame(df4[1:], columns=['reviewText', 'overall'])\n",
    "df15 = pd.DataFrame(df5[1:], columns=['reviewText', 'overall'])\n",
    "amazon = pd.concat([df11, df12, df13, df14, df15], ignore_index=True)\n",
    "amazon.reset_index(drop=True)\n",
    "\n",
    "text = amazon['reviewText']\n",
    "target = amazon['overall']\n",
    "\n",
    "clean_text = pd.Series(prep.preprocess_reviews(text))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(min_df=3, max_df=0.8, ngram_range=(1,5))\n",
    "\n",
    "# clf = MultinomialNB()\n",
    "# w = {1:2, 2:3, 3: 2, 4: 2, 5: 1 }\n",
    "clf = LogisticRegression(dual=False, random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "# clf = SVC(decision_function_shape=\"ovo\")\n",
    "# clf = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\n",
    "\n",
    "\n",
    "list_test = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "for i in list_test:\n",
    "    # Split dataset into training set and test set\n",
    "    test_size = i\n",
    "    train_size = 1 - i\n",
    "    X_train, X_test, y_train, y_test = train_test_split(clean_text, target, test_size=i,random_state=None)\n",
    "\n",
    "    # vectorizer = TfidfVectorizer(min_df=2 ,max_df=0.8, use_idf=True,sublinear_tf=True, ngram_range=(1,3))\n",
    "    vectorizer = CountVectorizer(min_df=2 ,max_df=0.8, ngram_range=(1,3))\n",
    "\n",
    "    train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "\n",
    "    print (\"Feature size of TF-IDF: \", len(vocab))\n",
    "    test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "    vectorizer_chi2 = SelectKBest(score_func=f_regression,k=3500)\n",
    "\n",
    "    chi_train_vectorized = vectorizer_chi2.fit_transform(train_vectorized,y_train)\n",
    "    chi_test_vectorized = vectorizer_chi2.transform(test_vectorized)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    # nb.fit(X_train, y_train)\n",
    "    clf.fit(chi_train_vectorized, y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(chi_test_vectorized)\n",
    "\n",
    "    print(\"Training and prediction done\")\n",
    "    print('Training target statistics: {}'.format(Counter(y_train), sorted(y_train)))\n",
    "    print('Testing target statistics: {}'.format(Counter(y_test), sorted(y_test)))\n",
    "\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"train: \" + str(train_size) + \"/ test: \" + str(test_size))\n",
    "    accuracy = str(metrics.accuracy_score(y_test, y_pred))\n",
    "    precision = str(metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "    f1 = str(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"Accuracy:\" + accuracy)\n",
    "    print(\"Precision:\" + precision)\n",
    "    print(\"F1:\" + f1)\n",
    "    print(pd.crosstab(y_test, y_pred))\n",
    "\n",
    "    # Visualization of Confusion Matrix and saving\n",
    "    plt.rcParams['figure.facecolor'] = 'white'\n",
    "    title = f\"Confusion matrix - Baseline(MNB, count(1,3), manually balanced, unprocessed, {train_size}_{test_size})\"\n",
    "    disp = plot_confusion_matrix(clf, chi_test_vectorized, y_test,\n",
    "                                 display_labels=[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "    disp.ax_.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "    title_norm = title + \"_normalize\"\n",
    "    disp_norm = plot_confusion_matrix(clf, chi_test_vectorized, y_test,\n",
    "                                 display_labels=[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "    disp_norm.ax_.set_title(title_norm)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('live', 0.995997268663658)\n",
      "('lancast', 0.9951785407935824)\n",
      "('boxset', 0.994616183867685)\n",
      "('caesar', 0.9944513193035504)\n",
      "('hay', 0.9944513193035504)\n",
      "('orang', 0.9944513193035504)\n",
      "('palmer', 0.9944513193035504)\n",
      "('patrol', 0.9944513193035504)\n",
      "('pq', 0.9944513193035504)\n",
      "('propheci', 0.9944513193035504)\n",
      "('clarkson', 0.9942119522789737)\n",
      "('eleanor', 0.9942119522789737)\n",
      "('orphanag', 0.9942119522789737)\n",
      "('person feel', 0.9942119522789737)\n",
      "('godzilla', 0.9940517323956107)\n",
      "('adjust', 0.9938602381998565)\n",
      "('altman', 0.9938602381998565)\n",
      "('amigo', 0.9938602381998565)\n",
      "('back littl', 0.9938602381998565)\n",
      "('beck', 0.9938602381998565)\n",
      "('bob dylan', 0.9938602381998565)\n",
      "('book howev', 0.9938602381998565)\n",
      "('burt lancast', 0.9938602381998565)\n",
      "('but turn', 0.9938602381998565)\n",
      "('car wash', 0.9938602381998565)\n",
      "('charact whose', 0.9938602381998565)\n",
      "('cigarett', 0.9938602381998565)\n",
      "('confer', 0.9938602381998565)\n",
      "('csi', 0.9938602381998565)\n",
      "('danc wolv', 0.9938602381998565)\n",
      "('elf', 0.9938602381998565)\n",
      "('elit', 0.9938602381998565)\n",
      "('elvi movi', 0.9938602381998565)\n",
      "('film age', 0.9938602381998565)\n",
      "('full screen', 0.9938602381998565)\n",
      "('glenda', 0.9938602381998565)\n",
      "('granddaught', 0.9938602381998565)\n",
      "('hatch', 0.9938602381998565)\n",
      "('holder', 0.9938602381998565)\n",
      "('jaff', 0.9938602381998565)\n",
      "('kiefer', 0.9938602381998565)\n",
      "('knew would', 0.9938602381998565)\n",
      "('loop', 0.9938602381998565)\n",
      "('michael sheen', 0.9938602381998565)\n",
      "('patricia clarkson', 0.9938602381998565)\n",
      "('play lisa', 0.9938602381998565)\n",
      "('prom', 0.9938602381998565)\n",
      "('scarier', 0.9938602381998565)\n",
      "('start season', 0.9938602381998565)\n",
      "('stuff happen', 0.9938602381998565)\n",
      "('three amigo', 0.9938602381998565)\n",
      "('three episod', 0.9938602381998565)\n",
      "('tint', 0.9938602381998565)\n",
      "('tom wilkinson', 0.9938602381998565)\n",
      "('tuck', 0.9938602381998565)\n",
      "('want buy', 0.9938602381998565)\n",
      "('watch around', 0.9938602381998565)\n",
      "('wilkinson', 0.9938602381998565)\n",
      "('world war two', 0.9938602381998565)\n",
      "('absenc', 0.9935274794985087)\n",
      "('act man', 0.9935274794985087)\n",
      "('action comedi', 0.9935274794985087)\n",
      "('action get', 0.9935274794985087)\n",
      "('actor get', 0.9935274794985087)\n",
      "('actor great', 0.9935274794985087)\n",
      "('actor like', 0.9935274794985087)\n",
      "('actor one', 0.9935274794985087)\n",
      "('actor thought', 0.9935274794985087)\n",
      "('actor would', 0.9935274794985087)\n",
      "('actual happen', 0.9935274794985087)\n",
      "('actual one', 0.9935274794985087)\n",
      "('actual see', 0.9935274794985087)\n",
      "('affleck', 0.9935274794985087)\n",
      "('afraid shadow', 0.9935274794985087)\n",
      "('ago but', 0.9935274794985087)\n",
      "('ago but not', 0.9935274794985087)\n",
      "('airport', 0.9935274794985087)\n",
      "('alistair', 0.9935274794985087)\n",
      "('allow viewer', 0.9935274794985087)\n",
      "('almost immedi', 0.9935274794985087)\n",
      "('almost year', 0.9935274794985087)\n",
      "('almost year ago', 0.9935274794985087)\n",
      "('alongsid', 0.9935274794985087)\n",
      "('alot action', 0.9935274794985087)\n",
      "('aloud', 0.9935274794985087)\n",
      "('alreadi said', 0.9935274794985087)\n",
      "('alright but not', 0.9935274794985087)\n",
      "('also add', 0.9935274794985087)\n",
      "('also contribut', 0.9935274794985087)\n",
      "('also need', 0.9935274794985087)\n",
      "('also set', 0.9935274794985087)\n",
      "('although mani', 0.9935274794985087)\n",
      "('alway big', 0.9935274794985087)\n",
      "('alway use', 0.9935274794985087)\n",
      "('amen', 0.9935274794985087)\n",
      "('american accent', 0.9935274794985087)\n",
      "('american man', 0.9935274794985087)\n",
      "('among other', 0.9935274794985087)\n",
      "('analysi', 0.9935274794985087)\n",
      "('angela lansburi', 0.9935274794985087)\n"
     ]
    }
   ],
   "source": [
    "# Get Features after Feature Selection\n",
    "# mask = vectorizer_chi2.get_support()\n",
    "# train_vectorized\n",
    "# new_features = []\n",
    "# mask = vectorizer_chi2.get_support() #list of booleans\n",
    "# new_features = [] # The list of your K best features\n",
    "#\n",
    "# for bool, feature in zip(mask, feature_names):\n",
    "#     if bool:\n",
    "#         new_features.append(feature)\n",
    "\n",
    "# vectorizer_chi2.fit(train_vectorized, y_train)\n",
    "# # Get columns to keep and create new dataframe with those only\n",
    "# cols = vectorizer_chi2.get_support(indices=True)\n",
    "# features_df_new = train_vectorized[:,cols]\n",
    "import numpy as np\n",
    "np.asarray(vectorizer.get_feature_names())[vectorizer_chi2.get_support()]\n",
    "top_ranked_features = sorted(enumerate(vectorizer_chi2.scores_),key=lambda x:x[1])[:100]\n",
    "top_ranked_features_indices = list(map(list,zip(*top_ranked_features)))[0]\n",
    "for feature_pvalue in zip(np.asarray(vectorizer.get_feature_names())[top_ranked_features_indices], vectorizer_chi2.pvalues_[top_ranked_features_indices]):\n",
    "    print(feature_pvalue)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 828)\t1\n",
      "  (0, 1809)\t2\n",
      "  (0, 1844)\t1\n",
      "  (0, 2301)\t1\n",
      "  (0, 2722)\t1\n",
      "  (0, 3636)\t1\n",
      "  (0, 3640)\t1\n",
      "  (0, 4100)\t1\n",
      "  (0, 4105)\t1\n",
      "  (0, 4148)\t1\n",
      "  (0, 4488)\t1\n",
      "  (0, 4800)\t3\n",
      "  (0, 4829)\t2\n"
     ]
    }
   ],
   "source": [
    "print(features_df_new[0])\n",
    "# print(mask[])\n",
    "# print(vectorizer.get_feature_names()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Training target statistics: {}'.format(Counter(target), sorted(target)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 425, in fit\n",
      "    dtype=[np.float64, np.float32])\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 803, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 579, in check_array\n",
      "    accept_large_sparse=accept_large_sparse)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 354, in _ensure_sparse_format\n",
      "    raise TypeError('A sparse matrix was passed, but dense '\n",
      "TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 210, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 803, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 579, in check_array\n",
      "    accept_large_sparse=accept_large_sparse)\n",
      "  File \"c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 354, in _ensure_sparse_format\n",
      "    raise TypeError('A sparse matrix was passed, but dense '\n",
      "TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.095058 (0.025834)\n",
      "SDG: 0.098031 (0.026703)\n",
      "LDA: nan (nan)\n",
      "KNN: 0.047061 (0.028415)\n",
      "CART: 0.063673 (0.017715)\n",
      "MNB: 0.104914 (0.031478)\n",
      "GNB: nan (nan)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-60-82113a78d28c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[0mkfold\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_selection\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mKFold\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_splits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m         \u001B[0mcv_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_selection\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcross_val_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchi_text_vectorized\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkfold\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscoring\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m         \u001B[0mresults\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcv_results\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[0mnames\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     71\u001B[0m                           FutureWarning)\n\u001B[0;32m     72\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    404\u001B[0m                                 \u001B[0mfit_params\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    405\u001B[0m                                 \u001B[0mpre_dispatch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpre_dispatch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 406\u001B[1;33m                                 error_score=error_score)\n\u001B[0m\u001B[0;32m    407\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mcv_results\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'test_score'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    408\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     71\u001B[0m                           FutureWarning)\n\u001B[0;32m     72\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    246\u001B[0m             \u001B[0mreturn_times\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_estimator\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mreturn_estimator\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m             error_score=error_score)\n\u001B[1;32m--> 248\u001B[1;33m         for train, test in cv.split(X, y, groups))\n\u001B[0m\u001B[0;32m    249\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    250\u001B[0m     \u001B[0mzipped_scores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mscores\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1030\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1031\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1032\u001B[1;33m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1033\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1034\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    845\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    846\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 847\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    848\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    763\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    764\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 765\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    766\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    767\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    205\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 206\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    207\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    208\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    568\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    251\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    252\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 253\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    254\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    255\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    251\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    252\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 253\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    254\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    255\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    529\u001B[0m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    530\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 531\u001B[1;33m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    532\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    533\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\svm\\_base.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    216\u001B[0m         \u001B[0mseed\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrnd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miinfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'i'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 217\u001B[1;33m         \u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msolver_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkernel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_seed\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    218\u001B[0m         \u001B[1;31m# see comment on the other call to np.iinfo in this file\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\svm\\_base.py\u001B[0m in \u001B[0;36m_sparse_fit\u001B[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001B[0m\n\u001B[0;32m    296\u001B[0m                 \u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcache_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepsilon\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    297\u001B[0m                 \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshrinking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprobability\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_iter\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 298\u001B[1;33m                 random_seed)\n\u001B[0m\u001B[0;32m    299\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    300\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_warn_from_fit_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32msklearn\\svm\\_libsvm_sparse.pyx\u001B[0m in \u001B[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, arg1, shape, dtype, copy)\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[1;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m         \u001B[0m_data_matrix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(dual=False, random_state=10)))\n",
    "models.append(('SDG', SGDClassifier()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'f1_macro'\n",
    "vectorizer = CountVectorizer(min_df=2 ,max_df=0.8, ngram_range=(1,3))\n",
    "text_vectorized = vectorizer.fit_transform(clean_text)\n",
    "# vectorizer_chi2 = SelectKBest(chi2,k=3000)\n",
    "vectorizer_chi2 = SelectKBest(score_func=f_classif, k=3500)\n",
    "chi_text_vectorized = vectorizer_chi2.fit_transform(text_vectorized,target)\n",
    "seed = 7\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, chi_text_vectorized, target, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}