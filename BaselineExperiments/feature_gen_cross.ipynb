{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_classif, f_regression\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 reviews per class from ../Data/amazon_phone.pkl loaded\n"
     ]
    }
   ],
   "source": [
    "from Scripts import loading as dl\n",
    "amazon_link = '../Data/amazon_phone.pkl'\n",
    "df = dl.load_sampled(amazon_link, 10000)\n",
    "\n",
    "target = df.label\n",
    "text = df.text\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.25,random_state=None)\n",
    "# # unigrams\n",
    "# vect = CountVectorizer()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  8.5min\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "param_grid = [{'vect__ngram_range': [(1,2), (1,3)],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [ 0.1, 1.0, 10.0],\n",
    "               'clf__multi_class': ['ovr', 'multinomial']\n",
    "               }]\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring='accuracy',\n",
    "                           cv=5, verbose=1, n_jobs=-1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'clf__C': 1.0,\n 'clf__multi_class': 'ovr',\n 'clf__penalty': 'l2',\n 'vect__ngram_range': (1, 1)}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# feature occurence\n",
    "vect = CountVectorizer(ngram_range=(1,3), binary=False)\n",
    "# feature occurence\n",
    "count = CountVectorizer(ngram_range=(1,3), binary=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "using text_prep\n",
    "\n",
    "features\n",
    "unigram (),\n",
    "bigram\n",
    "trigram\n",
    "uni + bi\n",
    "bi + tri\n",
    "binary 1-3\n",
    "count 1-3\n",
    "tfidf 1-3\n",
    "\n",
    "max 80, 90\n",
    "min 2, 5\n",
    "vocabulary size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "models.append(('LR', LogisticRegression(dual=False, random_state=10, multi_class='multinomial')))\n",
    "models.append(('SDG', SGDClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "results = []\n",
    "names = []\n",
    "# scoring = 'f1_macro'\n",
    "scoring = 'accuracy'\n",
    "vectorizer = CountVectorizer(min_df=2 ,max_df=0.8, ngram_range=(1,3))\n",
    "text_vectorized = vectorizer.fit_transform(text)\n",
    "# vectorizer_chi2 = SelectKBest(chi2,k=3000)\n",
    "vectorizer_chi2 = SelectKBest(score_func=f_classif, k=3500)\n",
    "chi_text_vectorized = vectorizer_chi2.fit_transform(text_vectorized,target)\n",
    "seed = 7\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, chi_text_vectorized, target, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}