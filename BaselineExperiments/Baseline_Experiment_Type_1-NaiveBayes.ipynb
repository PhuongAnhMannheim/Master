{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Experiment Type 1\n",
    "## Naive Bayes Theory\n",
    "\"Naive Bayes is a statistical classification technique based on Bayes Theorem. It is one of the simplest supervised learning algorithms. Naive Bayes classifier is the fast, accurate and reliable algorithm. Naive Bayes classifiers have high accuracy and speed on large datasets.\n",
    "\n",
    "Naive Bayes classifier assumes that the effect of a particular feature in a class is independent of other features. For example, a loan applicant is desirable or not depending on his/her income, previous loan and transaction history, age, and location. Even if these features are interdependent, these features are still considered independently. This assumption simplifies computation, and that's why it is considered as naive. This assumption is called class conditional independence.\n",
    "\n",
    "\n",
    "P(h): the probability of hypothesis h being true (regardless of the data). This is known as the prior probability of h.\n",
    "P(D): the probability of the data (regardless of the hypothesis). This is known as the prior probability.\n",
    "P(h|D): the probability of hypothesis h given the data D. This is known as posterior probability.\n",
    "P(D|h): the probability of data d given that the hypothesis h was true. This is known as posterior probability.\n",
    "\n",
    "How Naive Bayes classifier works?\"\n",
    "frequency and likelihood -> prior and posterior probability calculation -> calculation of conditional probability -> multiplication of same class conditional probability\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
    "## Advantages\n",
    "\n",
    "- It is not only a simple approach but also a fast and accurate method for prediction.               \n",
    "- Naive Bayes has very low computation cost.                          \n",
    "- It can efficiently work on a large dataset.  \n",
    "- It performs well in case of discrete response variable compared to the continuous variable.\n",
    "- It can be used with multiple class prediction problems. \n",
    "- It also performs well in the case of# text analytics problems. \n",
    "- When the assumption of independence holds, a Naive Bayes classifier performs better compared to other models like logistic regression.\n",
    "\n",
    "## Disadvantages\n",
    "- The assumption of independent features. In practice, it is almost impossible that model will get a set of predictors which are entirely independent.\n",
    "- If there is no training tuple of a particular class, this causes zero posterior probability. In this case, the model is unable to make predictions. This problem is known as Zero Probability/Frequency Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Coding: Amazon Movies & TV using Naive Bayes\n",
    "Used Dataset: \"Small\" subset of Amazon product data for Movies and TV\n",
    "structure: \n",
    "- reviewerID\n",
    "- asin\n",
    "- reviewerName\n",
    "- helpful\n",
    "- reviewText\n",
    "- overall\n",
    "- summary\n",
    "- unixReviewTime\n",
    "- reviewTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Start with importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:25:36.695261Z",
     "start_time": "2020-05-18T08:25:36.690258Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T08:37:53.894571Z",
     "start_time": "2020-05-14T08:34:14.182430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-14 08:34:14--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Movies_and_TV_5.json.gz\n",
      "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
      "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 708988936 (676M) [application/x-gzip]\n",
      "Saving to: ‘reviews_Movies_and_TV_5.json.gz’\n",
      "\n",
      "reviews_Movies_and_ 100%[===================>] 676.14M  3.76MB/s    in 3m 38s  \n",
      "\n",
      "2020-05-14 08:37:53 (3.10 MB/s) - ‘reviews_Movies_and_TV_5.json.gz’ saved [708988936/708988936]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Movies_and_TV_5.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T09:05:46.612989Z",
     "start_time": "2020-05-18T09:03:24.600874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194439\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with gzip.open('../Data/reviews_Cell_Phones_and_Accessories_5.json.gz') as f:\n",
    "    for l in f: \n",
    "        data.append(json.loads(l.strip()))\n",
    "\n",
    "# total length of list, this number equals total number of movie/tv reviews\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T09:03:02.883397Z",
     "start_time": "2020-05-18T09:02:59.350079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       reviewerID        asin      reviewerName helpful  \\\n0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n\n                                          reviewText  overall  \\\n0  They look good and stick good! I just don't li...      4.0   \n1  These stickers work like the review says they ...      5.0   \n2  These are awesome and make my phone look so st...      5.0   \n3  Item arrived in great time and was in perfect ...      4.0   \n4  awesome! stays on, and looks great. can be use...      5.0   \n\n                                     summary  unixReviewTime   reviewTime  \n0                                 Looks Good      1400630400  05 21, 2014  \n1                      Really great product.      1389657600  01 14, 2014  \n2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n3                                      Cute!      1382313600  10 21, 2013  \n4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>helpful</th>\n      <th>reviewText</th>\n      <th>overall</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>reviewTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A30TL5EWN6DFXT</td>\n      <td>120401325X</td>\n      <td>christina</td>\n      <td>[0, 0]</td>\n      <td>They look good and stick good! I just don't li...</td>\n      <td>4.0</td>\n      <td>Looks Good</td>\n      <td>1400630400</td>\n      <td>05 21, 2014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ASY55RVNIL0UD</td>\n      <td>120401325X</td>\n      <td>emily l.</td>\n      <td>[0, 0]</td>\n      <td>These stickers work like the review says they ...</td>\n      <td>5.0</td>\n      <td>Really great product.</td>\n      <td>1389657600</td>\n      <td>01 14, 2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A2TMXE2AFO7ONB</td>\n      <td>120401325X</td>\n      <td>Erica</td>\n      <td>[0, 0]</td>\n      <td>These are awesome and make my phone look so st...</td>\n      <td>5.0</td>\n      <td>LOVE LOVE LOVE</td>\n      <td>1403740800</td>\n      <td>06 26, 2014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AWJ0WZQYMYFQ4</td>\n      <td>120401325X</td>\n      <td>JM</td>\n      <td>[4, 4]</td>\n      <td>Item arrived in great time and was in perfect ...</td>\n      <td>4.0</td>\n      <td>Cute!</td>\n      <td>1382313600</td>\n      <td>10 21, 2013</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATX7CZYFXI1KW</td>\n      <td>120401325X</td>\n      <td>patrice m rogoza</td>\n      <td>[2, 3]</td>\n      <td>awesome! stays on, and looks great. can be use...</td>\n      <td>5.0</td>\n      <td>leopard home button sticker for iphone 4s</td>\n      <td>1359849600</td>\n      <td>02 3, 2013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert list into pandas dataframe\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T08:46:13.664972Z",
     "start_time": "2020-05-14T08:46:13.634403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ADZPIG9QOCDG5</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>Alice L. Larson \"alice-loves-books\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a charming version of the classic Dick...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>good version of a classic</td>\n",
       "      <td>1203984000</td>\n",
       "      <td>02 26, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A35947ZP82G7JH</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>Amarah Strack</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>It was good but not as emotionally moving as t...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Good but not as moving</td>\n",
       "      <td>1388361600</td>\n",
       "      <td>12 30, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A3UORV8A9D5L2E</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Don't get me wrong, Winkler is a wonderful cha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Winkler's Performance was ok at best!</td>\n",
       "      <td>1388361600</td>\n",
       "      <td>12 30, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A1VKW06X1O2X7V</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>Amazon Customer \"Softmill\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Henry Winkler is very good in this twist on th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It's an enjoyable twist on the classic story</td>\n",
       "      <td>1202860800</td>\n",
       "      <td>02 13, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A3R27T4HADWFFJ</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>BABE</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is one of the best Scrooge movies out.  H...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Best Scrooge yet</td>\n",
       "      <td>1387670400</td>\n",
       "      <td>12 22, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                         reviewerName helpful  \\\n",
       "0   ADZPIG9QOCDG5  0005019281  Alice L. Larson \"alice-loves-books\"  [0, 0]   \n",
       "1  A35947ZP82G7JH  0005019281                        Amarah Strack  [0, 0]   \n",
       "2  A3UORV8A9D5L2E  0005019281                      Amazon Customer  [0, 0]   \n",
       "3  A1VKW06X1O2X7V  0005019281           Amazon Customer \"Softmill\"  [0, 0]   \n",
       "4  A3R27T4HADWFFJ  0005019281                                 BABE  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This is a charming version of the classic Dick...      4.0   \n",
       "1  It was good but not as emotionally moving as t...      3.0   \n",
       "2  Don't get me wrong, Winkler is a wonderful cha...      3.0   \n",
       "3  Henry Winkler is very good in this twist on th...      5.0   \n",
       "4  This is one of the best Scrooge movies out.  H...      4.0   \n",
       "\n",
       "                                        summary  unixReviewTime   reviewTime  \n",
       "0                     good version of a classic      1203984000  02 26, 2008  \n",
       "1                        Good but not as moving      1388361600  12 30, 2013  \n",
       "2         Winkler's Performance was ok at best!      1388361600  12 30, 2013  \n",
       "3  It's an enjoyable twist on the classic story      1202860800  02 13, 2008  \n",
       "4                              Best Scrooge yet      1387670400  12 22, 2013  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:25:17.102224Z",
     "start_time": "2020-05-18T08:25:17.054058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1697533\n"
     ]
    }
   ],
   "source": [
    "target = df['overall']\n",
    "text = df['reviewText']\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:25:44.012257Z",
     "start_time": "2020-05-18T08:25:43.932408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "\n",
    "# label encode the target variable\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T14:05:52.892278Z",
     "start_time": "2020-05-17T14:05:52.870172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 2, 3, 4], dtype=int64)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.unique(y_train)\n",
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:27:17.992516Z",
     "start_time": "2020-05-18T08:26:44.454128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Extraction: Bag of Words with TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "tfidf_vect.fit(text)\n",
    "\n",
    "# transform the training and validation data using tfidf vectorizer object\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:27:25.880516Z",
     "start_time": "2020-05-18T08:27:25.875341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x86756 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 36 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:27:33.390388Z",
     "start_time": "2020-05-18T08:27:33.387839Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create a Binomial Classifier\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:27:41.379401Z",
     "start_time": "2020-05-18T08:27:41.128296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MultinomialNB()"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "nb.fit(xtrain_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = nb.predict(xtest_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    48      2     22     87  30730]\n",
      " [     9      0     30    207  30506]\n",
      " [     1      0     61    450  59907]\n",
      " [     7      2     53    550 114441]\n",
      " [    33     15     67    450 271582]]\n",
      "Accuracy: 0.5345815496995641\n",
      "Precision: 0.32049096647049036\n",
      "F1: 0.14230111562625974\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "# with CountVectorizer -> accuracy:  0.5956407336134784\n",
    "# with TFIDF Vectorizer -> Accuracy: 0.5594527874922856"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    48      2     22     87  30730]\n",
      " [     9      0     30    207  30506]\n",
      " [     1      0     61    450  59907]\n",
      " [     7      2     53    550 114441]\n",
      " [    33     15     67    450 271582]]\n"
     ]
    }
   ],
   "source": [
    "df_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(df_confusion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-24-711bb13a8429>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mFN\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_confusion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiag\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_confusion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mTP\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiag\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_confusion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mTN\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_confusion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mFP\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mFN\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mTP\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mFP\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mFN\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "FP = df_confusion.sum(axis=0) - np.diag(df_confusion)\n",
    "FN = df_confusion.sum(axis=1) - np.diag(df_confusion)\n",
    "TP = np.diag(df_confusion)\n",
    "TN = df_confusion.values.sum() - (FP + FN + TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TP)\n",
    "print(TN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-11c367f4ae1a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mFP\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiag\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mFN\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiag\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mTP\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiag\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mTN\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mFP\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mFN\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mTP\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"FP: \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mFP\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'function' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "print(\"FP: \" + FP)\n",
    "print(\"FP: \" + FN)\n",
    "print(\"FP: \" + TP)\n",
    "print(\"FP: \" + TN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Python Coding: Amazon Movies & TV using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T14:17:38.208627Z",
     "start_time": "2020-05-17T14:17:28.108884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-17 14:17:29--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz\n",
      "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
      "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45409631 (43M) [application/x-gzip]\n",
      "Saving to: ‘reviews_Cell_Phones_and_Accessories_5.json.gz’\n",
      "\n",
      "reviews_Cell_Phones 100%[===================>]  43.31M  6.10MB/s    in 8.4s    \n",
      "\n",
      "2020-05-17 14:17:38 (5.18 MB/s) - ‘reviews_Cell_Phones_and_Accessories_5.json.gz’ saved [45409631/45409631]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:30:43.002552Z",
     "start_time": "2020-05-18T08:30:36.803318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194439\n",
      "{'reviewerID': 'A30TL5EWN6DFXT', 'asin': '120401325X', 'reviewerName': 'christina', 'helpful': [0, 0], 'reviewText': \"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\", 'overall': 4.0, 'summary': 'Looks Good', 'unixReviewTime': 1400630400, 'reviewTime': '05 21, 2014'}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with gzip.open('reviews_Cell_Phones_and_Accessories_5.json.gz') as f: \n",
    "    for l in f: \n",
    "        data.append(json.loads(l.strip()))\n",
    "\n",
    "# total length of list, this number equals total number of movie/tv reviews\n",
    "print(len(data))\n",
    "\n",
    "# first row of the list\n",
    "print(data[0])\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:30:51.027978Z",
     "start_time": "2020-05-18T08:30:50.687234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194439\n",
      "  (0, 8864)\t1\n",
      "  (0, 9252)\t1\n",
      "  (0, 9782)\t1\n",
      "  (0, 16238)\t1\n",
      "  (0, 23509)\t1\n",
      "  (0, 23761)\t1\n",
      "  (0, 33608)\t1\n",
      "  (0, 34171)\t1\n",
      "  (0, 37033)\t1\n",
      "  (0, 39553)\t2\n",
      "  (0, 40618)\t1\n",
      "  (0, 42632)\t2\n",
      "  (0, 42864)\t4\n",
      "  (0, 43878)\t1\n",
      "  (0, 44431)\t1\n",
      "  (0, 45950)\t1\n",
      "  (0, 46713)\t1\n",
      "  (0, 47295)\t1\n",
      "  (0, 51175)\t2\n",
      "  (0, 52793)\t1\n",
      "  (0, 52881)\t1\n",
      "  (0, 53584)\t1\n",
      "  (0, 57502)\t1\n",
      "  (0, 57869)\t1\n",
      "  (0, 66298)\t2\n",
      "  (0, 68758)\t1\n",
      "  (0, 69619)\t1\n",
      "  (0, 75555)\t1\n",
      "  (0, 76237)\t2\n",
      "  (0, 76305)\t2\n",
      "  (0, 81835)\t1\n",
      "  (0, 84266)\t1\n",
      "  (0, 84324)\t1\n",
      "  (0, 84981)\t1\n",
      "  (0, 85060)\t1\n",
      "  (0, 85716)\t1\n"
     ]
    }
   ],
   "source": [
    "target = df['overall']\n",
    "text = df['reviewText']\n",
    "print(len(text))\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "\n",
    "# label encode the target variable\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "print(xtrain_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:30:58.737980Z",
     "start_time": "2020-05-18T08:30:58.722233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\n"
     ]
    }
   ],
   "source": [
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:34:56.529398Z",
     "start_time": "2020-05-18T08:34:21.854022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Extraction: Bag of Words with TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "tfidf_vect.fit(text)\n",
    "\n",
    "# transform the training and validation data using tfidf vectorizer object\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "nb.fit(xtrain_tfidf, y_train)\n",
    "y_pred = nb.predict(xtest_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:35:10.008659Z",
     "start_time": "2020-05-18T08:35:09.959325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5594527874922856\n",
      "Precision: 0.29114904143475573\n",
      "F1: 0.1453772850881709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"F1:\", metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "# with CountVectorizer -> Accuracy: 0.6152712061989989"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}