{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Scripts import preprocessing as prep\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# amazon_link = '../Data/amazon_phone.pkl'\n",
    "amazon_link = '../Data/amazon_movie.pkl'\n",
    "df = pd.read_pickle(amazon_link)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df.text = prep.preprocess_reviews(df.text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text, df.label, test_size=0.25,random_state=7, stratify=df.label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({5.0: 677719, 4.0: 286691, 3.0: 150697, 1.0: 77993, 2.0: 76680})\n",
      "Testing target statistics: Counter({5.0: 225907, 4.0: 95564, 3.0: 50232, 1.0: 25998, 2.0: 25560})\n"
     ]
    }
   ],
   "source": [
    "print('Training target statistics: {}'.format(Counter(y_train), sorted(y_train)))\n",
    "print('Testing target statistics: {}'.format(Counter(y_test), sorted(y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-31-b665570f027a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mvectorizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTfidfVectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmin_df\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmax_df\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.9\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mngram_range\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# vectorizer = CountVectorizer(min_df=5,max_df=0.9, ngram_range=(1,3))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtrain_vectorized\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvectorizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m\"Feature size of TF-IDF: \"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvectorizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_feature_names\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mtest_vectorized\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvectorizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1838\u001B[0m         \"\"\"\n\u001B[0;32m   1839\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1840\u001B[1;33m         \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mraw_documents\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1841\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tfidf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1842\u001B[0m         \u001B[1;31m# X is already a transformed view of raw_documents so\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1197\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1198\u001B[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001B[1;32m-> 1199\u001B[1;33m                                           self.fixed_vocabulary_)\n\u001B[0m\u001B[0;32m   1200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1201\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbinary\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36m_count_vocab\u001B[1;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[0;32m   1119\u001B[0m                     \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1120\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1121\u001B[1;33m             \u001B[0mj_indices\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeature_counter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1122\u001B[0m             \u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeature_counter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1123\u001B[0m             \u001B[0mindptr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mj_indices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5,max_df=0.9, ngram_range=(1,3))\n",
    "# vectorizer = CountVectorizer(min_df=5,max_df=0.9, ngram_range=(1,3))\n",
    "train_vectorized = vectorizer.fit_transform(X_train)\n",
    "print (\"Feature size of TF-IDF: \", len(vectorizer.get_feature_names()))\n",
    "test_vectorized = vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer_fs = SelectKBest(score_func=f_classif, k=1000)\n",
    "fs_train_vectorized = vectorizer_fs.fit_transform(train_vectorized,y_train)\n",
    "fs_test_vectorized = vectorizer_fs.transform(test_vectorized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1.0, dual=False, fit_intercept=True, random_state=0, solver='lbfgs', intercept_scaling=1, max_iter=100, multi_class='multinomial', class_weight='balanced')\n",
    "clf.fit(fs_train_vectorized, y_train)\n",
    "y_pred = clf.predict(fs_test_vectorized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = str(metrics.accuracy_score(y_test, y_pred))\n",
    "precision = str(metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "f1 = str(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Accuracy:\" + accuracy)\n",
    "print(\"Precision:\" + precision)\n",
    "print(\"F1:\" + f1)\n",
    "print(pd.crosstab(y_test, y_pred))\n",
    "\n",
    "# Visualization of Confusion Matrix and saving\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "title = f\"Confusion matrix 75_25)\"\n",
    "disp = plot_confusion_matrix(clf, fs_test_vectorized, y_test,\n",
    "                             display_labels=[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                             cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(title)\n",
    "plt.show()\n",
    "\n",
    "title_norm = title + \"_normalize\"\n",
    "disp_norm = plot_confusion_matrix(clf, fs_test_vectorized, y_test,\n",
    "                             display_labels=[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true')\n",
    "disp_norm.ax_.set_title(title_norm)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For Movie (Countvectorizer)\n",
    "# Accuracy:0.5884855916325861\n",
    "# Precision:0.46344580886772385\n",
    "# F1:0.48193706273773207\n",
    "\n",
    "\n",
    "# For Phone (Complete)\n",
    "# Accuracy:0.5967368855844692\n",
    "# Precision:0.45642294744267653\n",
    "# F1:0.4737592372355196"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}