{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 reviews per class from ../Data/amazon_phone.pkl loaded\n",
      "######## RUN SVC\n",
      "Fitting 5 folds for each of 255 candidates, totalling 1275 fits\n",
      "best parameters\n",
      "{'vect': CountVectorizer(max_df=0.75, min_df=3, ngram_range=(1, 3)), 'vect__max_df': 0.75, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}\n",
      "best score\n",
      "0.2608985994935652\n",
      "    vect__binary  vect__max_df  vect__min_df vect__ngram_range  \\\n",
      "0           True           0.5             1            (1, 1)   \n",
      "1           True           0.5             1            (1, 2)   \n",
      "2           True           0.5             1            (1, 3)   \n",
      "3           True           0.5             2            (1, 1)   \n",
      "4           True           0.5             2            (1, 2)   \n",
      "..           ...           ...           ...               ...   \n",
      "250          NaN           1.0             5            (1, 2)   \n",
      "251          NaN           1.0             5            (1, 3)   \n",
      "252          NaN           1.0            10            (1, 1)   \n",
      "253          NaN           1.0            10            (1, 2)   \n",
      "254          NaN           1.0            10            (1, 3)   \n",
      "\n",
      "                                                  vect  f1_macro  \n",
      "0                                                  NaN  0.137026  \n",
      "1                                                  NaN  0.095720  \n",
      "2                                                  NaN  0.086441  \n",
      "3                                                  NaN  0.178807  \n",
      "4                                                  NaN  0.152680  \n",
      "..                                                 ...       ...  \n",
      "250  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.224263  \n",
      "251  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.224263  \n",
      "252  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.194384  \n",
      "253  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.205786  \n",
      "254  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.205786  \n",
      "\n",
      "[255 rows x 6 columns]\n",
      "######## RUN LOGISTIC REGRESSION\n",
      "Fitting 5 folds for each of 255 candidates, totalling 1275 fits\n",
      "best parameters\n",
      "{'vect__binary': True, 'vect__max_df': 0.75, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}\n",
      "best score\n",
      "0.3069916175778245\n",
      "    vect__binary  vect__max_df  vect__min_df vect__ngram_range  \\\n",
      "0           True           0.5             1            (1, 1)   \n",
      "1           True           0.5             1            (1, 2)   \n",
      "2           True           0.5             1            (1, 3)   \n",
      "3           True           0.5             2            (1, 1)   \n",
      "4           True           0.5             2            (1, 2)   \n",
      "..           ...           ...           ...               ...   \n",
      "250          NaN           1.0             5            (1, 2)   \n",
      "251          NaN           1.0             5            (1, 3)   \n",
      "252          NaN           1.0            10            (1, 1)   \n",
      "253          NaN           1.0            10            (1, 2)   \n",
      "254          NaN           1.0            10            (1, 3)   \n",
      "\n",
      "                                                  vect  f1_macro  \n",
      "0                                                  NaN  0.216811  \n",
      "1                                                  NaN  0.159800  \n",
      "2                                                  NaN  0.142472  \n",
      "3                                                  NaN  0.264940  \n",
      "4                                                  NaN  0.253913  \n",
      "..                                                 ...       ...  \n",
      "250  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.257424  \n",
      "251  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.257424  \n",
      "252  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.243461  \n",
      "253  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.244612  \n",
      "254  CountVectorizer(max_df=0.75, min_df=3, ngram_r...  0.244612  \n",
      "\n",
      "[255 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 864 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1275 out of 1275 | elapsed:   17.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1260 out of 1275 | elapsed:   21.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1275 out of 1275 | elapsed:   22.0s finished\n",
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "amazon_link = '../Data/amazon_phone.pkl'\n",
    "\n",
    "# ToDo: reference to module\n",
    "# from Scripts import loading as dl\n",
    "# df = dl.load_sampled(amazon_link, 5000)\n",
    "def load_sampled(link, per_class):\n",
    "    df = pd.read_pickle(link)\n",
    "    df_1 = df[df['label'] == 1.0].values.tolist()\n",
    "    df_2 = df[df['label'] == 2.0].values.tolist()\n",
    "    df_3 = df[df['label'] == 3.0].values.tolist()\n",
    "    df_4 = df[df['label'] == 4.0].values.tolist()\n",
    "    df_5 = df[df['label'] == 5.0].values.tolist()\n",
    "\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf1 = random.sample(df_1, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf1 = random.choices(df_1, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf2 = random.sample(df_2, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf2 = random.choices(df_2, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf3 = random.sample(df_3, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf3 = random.choices(df_3, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf4 = random.sample(df_4, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf4 = random.choices(df_4, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf5 = random.sample(df_5, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf5 = random.choices(df_5, k=per_class)\n",
    "    adf11 = pd.DataFrame(adf1)\n",
    "    adf12 = pd.DataFrame(adf2)\n",
    "    adf13 = pd.DataFrame(adf3)\n",
    "    adf14 = pd.DataFrame(adf4)\n",
    "    adf15 = pd.DataFrame(adf5)\n",
    "    df_all = pd.concat([adf11, adf12, adf13, adf14, adf15], ignore_index=True)\n",
    "    df_all = df_all[[2, 1]]\n",
    "    df_all.columns = ['text_prep', 'label']\n",
    "    print(f'{per_class} reviews per class from {link} loaded')\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df = load_sampled(amazon_link, 5000)\n",
    "df = df.sample(frac=0.01)\n",
    "target = df.label\n",
    "text = df.text_prep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.3, random_state=None)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "param_grid = [{\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
    "    'vect__max_df': [0.5, 0.75, 0.8, 0.9, 1.0],\n",
    "    'vect__min_df': [1, 2, 3, 5, 10, 20],\n",
    "    'vect__binary': [True, False]\n",
    "}, {\n",
    "    'vect': [CountVectorizer(),],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
    "    'vect__max_df': [0.5, 0.75, 0.8, 0.9, 1.0],\n",
    "    'vect__min_df': [1, 2, 3, 5, 10],\n",
    "\n",
    "}]\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "print('######## RUN SVC')\n",
    "svc_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', SVC(C=1.0, decision_function_shape='ovo', gamma='auto', kernel='linear', random_state=123))])\n",
    "gs_svc_features = GridSearchCV(svc_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_svc_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_svc_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_svc_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_svc_features.cv_results_[\"params\"]), pd.DataFrame(gs_svc_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])], axis=1))\n",
    "\n",
    "\n",
    "print('######## RUN LOGISTIC REGRESSION')\n",
    "lr_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', LogisticRegression(C=10.0, multi_class='multinomial', penalty='l2', solver='saga', random_state=123))])\n",
    "\n",
    "gs_lr_features = GridSearchCV(lr_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_lr_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_lr_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_lr_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_lr_features.cv_results_[\"params\"]),pd.DataFrame(gs_lr_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, mutual_info_classif, mutual_info_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "amazon_link = '../Data/amazon_phone.pkl'\n",
    "\n",
    "# ToDo: reference to module\n",
    "# from Scripts import loading as dl\n",
    "# df = dl.load_sampled(amazon_link, 5000)\n",
    "def load_sampled(link, per_class):\n",
    "    df = pd.read_pickle(link)\n",
    "    df_1 = df[df['label'] == 1.0].values.tolist()\n",
    "    df_2 = df[df['label'] == 2.0].values.tolist()\n",
    "    df_3 = df[df['label'] == 3.0].values.tolist()\n",
    "    df_4 = df[df['label'] == 4.0].values.tolist()\n",
    "    df_5 = df[df['label'] == 5.0].values.tolist()\n",
    "\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf1 = random.sample(df_1, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf1 = random.choices(df_1, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf2 = random.sample(df_2, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf2 = random.choices(df_2, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf3 = random.sample(df_3, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf3 = random.choices(df_3, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf4 = random.sample(df_4, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf4 = random.choices(df_4, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf5 = random.sample(df_5, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf5 = random.choices(df_5, k=per_class)\n",
    "    adf11 = pd.DataFrame(adf1)\n",
    "    adf12 = pd.DataFrame(adf2)\n",
    "    adf13 = pd.DataFrame(adf3)\n",
    "    adf14 = pd.DataFrame(adf4)\n",
    "    adf15 = pd.DataFrame(adf5)\n",
    "    df_all = pd.concat([adf11, adf12, adf13, adf14, adf15], ignore_index=True)\n",
    "    df_all = df_all[[0, 1]]\n",
    "    df_all.columns = ['text', 'label']\n",
    "    print(f'{per_class} reviews per class from {link} loaded')\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df = load_sampled(amazon_link, 5000)\n",
    "df.head()\n",
    "target = df.label\n",
    "text = df.text_prep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.3, random_state=None)\n",
    "\n",
    "count = CountVectorizer()\n",
    "kbest = SelectKBest(f_classif)\n",
    "param_grid = [{\n",
    "    'kbest__k': [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "}, {\n",
    "    'kbest': [SelectKBest(f_regression)],\n",
    "    'kbest__k': [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "}, {\n",
    "    'kbest': [SelectKBest(mutual_info_classif)],\n",
    "    'kbest__k': [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "}]\n",
    "\n",
    "ml_features = Pipeline([('vect', ???),\n",
    "                        ('clf', ???)])\n",
    "\n",
    "gs_ml_features = GridSearchCV(ml_features, param_grid, scoring='f1_macro',\n",
    "                              cv=5, verbose=1, n_jobs=-1)\n",
    "gs_ml_features.fit(X_train, y_train)\n",
    "print('all results:')\n",
    "print(gs_ml_features.cv_results_)\n",
    "print('best parameters')\n",
    "print(gs_ml_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_ml_features.best_score_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}