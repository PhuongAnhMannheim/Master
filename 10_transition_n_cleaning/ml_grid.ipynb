{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "amazon_link = '../Data/amazon_phone.pkl'\n",
    "\n",
    "# ToDo: reference to module\n",
    "# from Scripts import loading as dl\n",
    "# df = dl.load_sampled(amazon_link, 5000)\n",
    "def load_sampled(link, per_class):\n",
    "    df = pd.read_pickle(link)\n",
    "    df_1 = df[df['label'] == 1.0].values.tolist()\n",
    "    df_2 = df[df['label'] == 2.0].values.tolist()\n",
    "    df_3 = df[df['label'] == 3.0].values.tolist()\n",
    "    df_4 = df[df['label'] == 4.0].values.tolist()\n",
    "    df_5 = df[df['label'] == 5.0].values.tolist()\n",
    "\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf1 = random.sample(df_1, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf1 = random.choices(df_1, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf2 = random.sample(df_2, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf2 = random.choices(df_2, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf3 = random.sample(df_3, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf3 = random.choices(df_3, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf4 = random.sample(df_4, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf4 = random.choices(df_4, k=per_class)\n",
    "    try:\n",
    "        random.seed(123)\n",
    "        adf5 = random.sample(df_5, per_class)\n",
    "    except ValueError:\n",
    "        random.seed(123)\n",
    "        adf5 = random.choices(df_5, k=per_class)\n",
    "    adf11 = pd.DataFrame(adf1)\n",
    "    adf12 = pd.DataFrame(adf2)\n",
    "    adf13 = pd.DataFrame(adf3)\n",
    "    adf14 = pd.DataFrame(adf4)\n",
    "    adf15 = pd.DataFrame(adf5)\n",
    "    df_all = pd.concat([adf11, adf12, adf13, adf14, adf15], ignore_index=True)\n",
    "    df_all = df_all[[2, 1]]\n",
    "    df_all.columns = ['text_prep', 'label']\n",
    "    print(f'{per_class} reviews per class from {link} loaded')\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df = load_sampled(amazon_link, 5000)\n",
    "target = df.label\n",
    "text = df.text_prep\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.3, random_state=None)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "param_grid = [{\n",
    "    'vect__max_df': [0.5, 0.75, 0.8, 0.9, 1.0],\n",
    "    'vect__min_df': [1, 2, 3, 5, 10, 20],\n",
    "    'vect__binary': [True, False]\n",
    "}, {\n",
    "    'vect': [CountVectorizer(),],\n",
    "    'vect__max_df': [0.5, 0.75, 0.8, 0.9, 1.0],\n",
    "    'vect__min_df': [1, 2, 3, 5, 10],\n",
    "\n",
    "}]\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=False, random_state=123)\n",
    "print('######## RUN SVC')\n",
    "svc_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', SVC(C=1.0, decision_function_shape='ovo', gamma='auto', kernel='linear', random_state=123))])\n",
    "gs_svc_features = GridSearchCV(svc_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_svc_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_svc_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_svc_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_svc_features.cv_results_[\"params\"]),pd.DataFrame(gs_svc_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1))\n",
    "\n",
    "\n",
    "print('######## RUN LOGISTIC REGRESSION')\n",
    "lr_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', LogisticRegression(C=10.0, multi_class='multinomial', penalty='l2', solver='saga', random_state=123))])\n",
    "\n",
    "gs_lr_features = GridSearchCV(lr_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_lr_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_lr_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_lr_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_lr_features.cv_results_[\"params\"]),pd.DataFrame(gs_lr_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1))\n",
    "\n",
    "\n",
    "print('######## RUN SGDClassifier')\n",
    "sgd_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', SGDClassifier(alpha=0.0001, max_iter=500, penalty='l2', random_state=123, loss='hinge'))])\n",
    "\n",
    "gs_sgd_features = GridSearchCV(sgd_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_sgd_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_sgd_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_sgd_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_sgd_features.cv_results_[\"params\"]),pd.DataFrame(gs_sgd_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1))\n",
    "\n",
    "\n",
    "print('######## RUN Multinomial Bayes with prior')\n",
    "nb_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', MultinomialNB(alpha=1.0, fit_prior=False))])\n",
    "\n",
    "gs_nb_features = GridSearchCV(nb_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_nb_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_nb_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_nb_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_nb_features.cv_results_[\"params\"]),pd.DataFrame(gs_nb_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1))\n",
    "\n",
    "\n",
    "print('######## RUN Multinomial Bayes without prior')\n",
    "nb_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', MultinomialNB(alpha=1.0, fit_prior=False))])\n",
    "\n",
    "gs_nb_features = GridSearchCV(nb_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_nb_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_nb_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_nb_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_nb_features.cv_results_[\"params\"]),pd.DataFrame(gs_nb_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1))\n",
    "\n",
    "\n",
    "print('######## RUN Multinomial Bayes without prior')\n",
    "nb_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', MultinomialNB(alpha=1.0, fit_prior=False))])\n",
    "\n",
    "gs_nb_features = GridSearchCV(nb_features, param_grid, scoring='f1_macro', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_nb_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_nb_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_nb_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_nb_features.cv_results_[\"params\"]),pd.DataFrame(gs_nb_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1))\n",
    "\n",
    "\n",
    "print('######## RUN SVR')\n",
    "nb_features = Pipeline([('vect', tfidf),\n",
    "                        ('clf', SVR(C=10.0, gamma='scale', kernel='rbf', ))])\n",
    "\n",
    "gs_nb_features = GridSearchCV(nb_features, param_grid, scoring='neg_mean_squared_error', cv=cv, verbose=3, n_jobs=-1)\n",
    "gs_nb_features.fit(X_train, y_train)\n",
    "print('best parameters')\n",
    "print(gs_nb_features.best_params_)\n",
    "print('best score')\n",
    "print(gs_nb_features.best_score_)\n",
    "print(pd.concat([pd.DataFrame(gs_nb_features.cv_results_[\"params\"]),pd.DataFrame(gs_nb_features.cv_results_[\"mean_test_score\"], columns=[\"f1_macro\"])],axis=1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}