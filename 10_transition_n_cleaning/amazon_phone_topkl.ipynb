{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## FIRST GENERAL INSIGHT\n",
      "                                                text  label\n",
      "0  They look good and stick good! I just don't li...    4.0\n",
      "1  These stickers work like the review says they ...    5.0\n",
      "2  These are awesome and make my phone look so st...    5.0\n",
      "3  Item arrived in great time and was in perfect ...    4.0\n",
      "4  awesome! stays on, and looks great. can be use...    5.0\n",
      "######## Total: \n",
      "Amount of reviews:  194439\n",
      "######## DESCRIPTION\n",
      "          text          label\n",
      "count   194439  194439.000000\n",
      "unique  194186            NaN\n",
      "top                       NaN\n",
      "freq        99            NaN\n",
      "mean       NaN       4.129912\n",
      "std        NaN       1.222499\n",
      "min        NaN       1.000000\n",
      "25%        NaN       4.000000\n",
      "50%        NaN       5.000000\n",
      "75%        NaN       5.000000\n",
      "max        NaN       5.000000\n",
      "######## DATA COMPLETENESS\n",
      "Missing/Empty review text: 99\n",
      "Missing review text as percentage: 0.05% \n",
      "Missing rating information 0\n",
      "Missing rating information as percentage: 0.00%\n",
      "After removing implictly missing rating information:  194340\n",
      "######## DUPLICATE DETECTION\n",
      "Duplicate text: 155\n",
      "Duplicate text: 0.08%\n",
      "Duplicate text and label: 119\n",
      "Duplicate text and label from reviews without missing information: 0.06%\n",
      "After removing duplicate entries and texts:  194185\n",
      "######## LINGUISTIC AFFILIATION\n",
      "exception: &#1576;&#1589;&#1585;&#1575;&#1581;&#1607; &#1575;&#1606;&#1575; &#1605;&#1606; &#1610;&#1608;&#1605; &#1605;&#1575; &#1588;&#1585;&#1610;&#1578; &#1607;&#1584;&#1575; &#1575;&#1604;&#1605;&#1606;&#1578;&#1580; &#1608;&#1575;&#1606;&#1575; &#1587;&#1593;&#1610;&#1583; ... &#1608;&#1605;&#1585;&#1578;&#1575;&#1581; &#1604;&#1575;&#1606; &#1575;&#1604;&#1576;&#1591;&#1575;&#1585;&#1610;&#1607; &#1588;&#1594;&#1575;&#1604;&#1607; &#1593;&#1604;&#1609; &#1575;&#1603;&#1605;&#1604; &#1608;&#1580;&#1607; &#1608;&#1601;&#1593;&#1604;&#1609; &#1578;&#1587;&#1578;&#1575;&#1607;&#1604; &#1602;&#1610;&#1605;&#1578;&#1607;&#1575; &#1608;&#1575;&#1575;&#1610;&#1583; &#1607;&#1584;&#1610; &#1575;&#1604;&#1605;&#1575;&#1585;&#1603;&#1607; &#1604;&#1575;&#1606;&#1610; &#1580;&#1585;&#1576;&#1578; &#1593;&#1583;&#1577; &#1576;&#1591;&#1575;&#1585;&#1610;&#1575;&#1578; &#1579;&#1575;&#1606;&#1608;&#1610;&#1607; &#1608;&#1575;&#1601;&#1590;&#1604; &#1607;&#1584;&#1610; &#1575;&#1604;&#1605;&#1575;&#1585;&#1603;&#1607; &#1593;&#1606; &#1594;&#1610;&#1585;&#1607;&#1575; &#1605;&#1606; &#1608;&#1575;&#1602;&#1593; &#1578;&#1580;&#1585;&#1576;&#1607;\n",
      "exception: &#1575;&#1604;&#1580;&#1607;&#1575;&#1586; &#1605;&#1605;&#1578;&#1575;&#1586; &#1588;&#1581;&#1606; &#1605;&#1605;&#1578;&#1575;&#1586; &#1589;&#1608;&#1578; &#1580;&#1610;&#1583; &#1580;&#1583;&#1575; &#1608;&#1602;&#1583; &#1610;&#1603;&#1608;&#1606; &#1605;&#1605;&#1578;&#1575;&#1586; &#1608;&#1575;&#1604;&#1587;&#1593;&#1585; &#1605;&#1605;&#1578;&#1575;&#1586; &#1575;&#1604;&#1580;&#1607;&#1575;&#1586; &#1610;&#1587;&#1578;&#1581;&#1602; &#1575;&#1604;&#1578;&#1580;&#1585;&#1576;&#1607; &#1608;&#1587;&#1593;&#1585;&#1607; &#1581;&#1604;&#1608;&#1575;&#1604;&#1610; &#1604;&#1575;&#1581;&#1592;&#1578;&#1607; &#1601;&#1602;&#1591; &#1575;&#1606;&#1603; &#1603;&#1575;&#1606;&#1603; &#1578;&#1603;&#1604;&#1605; &#1593;&#1606; &#1605;&#1610;&#1603;&#1585;&#1601;&#1608;&#1606; &#1575;&#1604;&#1578;&#1604;&#1601;&#1608;&#1606; &#1606;&#1601;&#1587;&#1607; &#1576;&#1587; &#1575;&#1606;&#1575; &#1575;&#1587;&#1605;&#1593; &#1589;&#1608;&#1578; &#1575;&#1604;&#1605;&#1578;&#1589;&#1604; &#1576;&#1588;&#1603;&#1604; &#1605;&#1605;&#1578;&#1575;&#1586; &#1608;&#1575;&#1604;&#1610; &#1575;&#1603;&#1604;&#1605;&#1607; &#1610;&#1602;&#1608;&#1604; &#1589;&#1608;&#1578;&#1603; &#1580;&#1610;&#1583; &#1580;&#1583;&#1575; &#1580;&#1583;&#1575; &#1580;&#1583;&#1575; &#1576;&#1587; &#1603;&#1575;&#1606;&#1603; &#1578;&#1603;&#1604;&#1605; &#1593;&#1606; &#1591;&#1585;&#1610;&#1602; &#1575;&#1604;&#1605;&#1603;&#1585;&#1601;&#1608;&#1606; &#1576;&#1587; &#1589;&#1608;&#1578;&#1603; &#1608;&#1575;&#1590;&#1581; &#1608;&#1575;&#1606;&#1575; &#1575;&#1606;&#1589;&#1581; &#1576;&#1575;&#1604;&#1580;&#1607;&#1575;&#1586;\n",
      "exception: #2\n",
      "exception: &#1588;&#1603;&#1604;&#1607;&#1575; &#1605;&#1606;&#1575;&#1587;&#1576; , &#1608;&#1607;&#1610; &#1605;&#1606;&#1575;&#1587;&#1576;&#1607; &#1604;&#1604;&#1575;&#1610;&#1601;&#1608;&#1606; , &#1608;&#1603;&#1575;&#1606; &#1575;&#1604;&#1587;&#1593;&#1585; &#1585;&#1575;&#1574;&#1593; &#1580;&#1583;&#1575; &#1588;&#1603;&#1585;&#1575; &#1580;&#1586;&#1610;&#1604;&#1575; , &#1608;&#1608;&#1589;&#1604;&#1578; &#1576;&#1581;&#1575;&#1604;&#1577; &#1605;&#1605;&#1578;&#1575;&#1586;&#1577; &#1580;&#1583;&#1575; , &#1587;&#1571;&#1593;&#1608;&#1583; &#1604;&#1604;&#1588;&#1585;&#1575;&#1569; &#1605;&#1585;&#1577; &#1571;&#1582;&#1585;&#1609; &#1605;&#1606; &#1607;&#1584;&#1575; &#1575;&#1604;&#1576;&#1575;&#1574;&#1593;\n",
      "exception: &#20294; &#26159; &#25105; &#21487; &#20197; &#29702; &#35299; &#20320; &#20204; &#22240; &#20026; &#26159; &#20174; &#20013; &#22269; &#23492; &#20986; &#26469; &#30340; &#25105;&#34920;&#31034;&#30693;&#36947;&#20013;&#22269;&#37038;&#25919;&#30340;&#36895;&#24230;\n",
      "exception: &#1588;&#1603;&#1585;&#1575; &#1580;&#1586;&#1610;&#1604;&#1575; , &#1608;&#1589;&#1604;&#1578; &#1575;&#1604;&#1587;&#1604;&#1593;&#1577; &#1587;&#1604;&#1610;&#1605;&#1577; &#1603;&#1605;&#1575; &#1607;&#1610; &#1601;&#1610; &#1575;&#1604;&#1589;&#1608;&#1585;&#1577; , &#1582;&#1601;&#1610;&#1601;&#1577; &#1608;&#1605;&#1606;&#1575;&#1587;&#1576;&#1577; &#1580;&#1583;&#1575; &#1604;&#1604;&#1575;&#1610;&#1601;&#1608;&#1606; , &#1603;&#1575;&#1606;&#1578; &#1607;&#1583;&#1610;&#1577; &#1585;&#1575;&#1574;&#1593;&#1577; &#1604;&#1571;&#1589;&#1581;&#1575;&#1576;&#1610; , &#1575;&#1604;&#1587;&#1593;&#1585; &#1603;&#1575;&#1606; &#1605;&#1606;&#1575;&#1587;&#1576; &#1580;&#1583;&#1575;\n",
      "exception: &#1575;&#1604;&#1576;&#1591;&#1575;&#1585;&#1610;&#1607; &#1605;&#1605;&#1578;&#1575;&#1586;&#1607; &#1608;&#1575;&#1604;&#1609; &#1582;&#1604;&#1575;&#1606;&#1610; &#1605;&#1575;&#1593;&#1591;&#1610;&#1607;&#1575; &#1582;&#1605;&#1587; &#1606;&#1580;&#1608;&#1605; &#1604;&#1575;&#1606; &#1575;&#1604;&#1580;&#1607;&#1575;&#1586; &#1575;&#1587;&#1578;&#1582;&#1583;&#1605;&#1607; &#1605;&#1593; &#1582;&#1591; &#1575;&#1604;&#1579;&#1575;&#1606;&#1610; &#1608;&#1605;&#1575;&#1580;&#1585;&#1576;&#1578;&#1607; &#1603;&#1579;&#1610;&#1585; &#1604;&#1603;&#1606; &#1605;&#1605;&#1578;&#1575;&#1586;&#1607; &#1578;&#1591;&#1608;&#1604; &#1608;&#1578;&#1585;&#1610;&#1581;&#1603; &#1605;&#1606; &#1575;&#1604;&#1588;&#1581;&#1606; &#1582;&#1575;&#1589;&#1577; &#1601;&#1610; &#1575;&#1604;&#1587;&#1601;&#1585; &#1575;&#1604;&#1576;&#1591;&#1575;&#1585;&#1610;&#1607; &#1610;&#1580;&#1610; &#1605;&#1593;&#1607;&#1575; &#1603;&#1601;&#1585;&#1610;&#1606; &#1607;&#1604;&#1601;&#1610;&#1607; &#1608;&#1575;&#1581;&#1583; &#1575;&#1576;&#1610;&#1590; &#1608;&#1608;&#1575;&#1581;&#1583; &#1575;&#1586;&#1585;&#1602;.\n",
      "exception: &#1575;&#1606;&#1575; &#1575;&#1588;&#1608;&#1601; &#1575;&#1606;&#1607;&#1575; &#1586;&#1608;&#1610;&#1606;&#1607; &#1604;&#1575;&#1606;&#1607; &#1605;&#1593; &#1575;&#1604;&#1608;&#1602;&#1578; &#1578;&#1581;&#1585;&#1603; &#1608;&#1610;&#1580;&#1610; &#1601;&#1610;&#1607;&#1575; &#1608;&#1589;&#1582; &#1608;&#1578;&#1581;&#1578;&#1575;&#1580; &#1604;&#1575;&#1606;&#1578;&#1576;&#1575;&#1607; &#1575;&#1579;&#1606;&#1575;&#1569; &#1578;&#1585;&#1603;&#1610;&#1576;&#1607;&#1575; &#1575;&#1604;&#1581;&#1604;&#1608; &#1601;&#1610;&#1607;&#1575; &#1575;&#1606;&#1607;&#1575; &#1578;&#1581;&#1605;&#1610; &#1575;&#1604;&#1580;&#1607;&#1575;&#1586; &#1603;&#1604;&#1607;&#1575; &#1605;&#1606; &#1593;&#1604;&#1609; &#1580;&#1606;&#1576; &#1608;&#1575;&#1604;&#1575;&#1591;&#1585;&#1575;&#1601; &#1608;&#1575;&#1605;&#1575;&#1605; &#1608;&#1582;&#1604;&#1601;\n",
      "exception: &#1575;&#1604;&#1603;&#1601;&#1585; &#1581;&#1604;&#1608; &#1608;&#1575;&#1604;&#1581;&#1604;&#1608; &#1601;&#1610;&#1607; &#1575;&#1606;&#1607; &#1590;&#1593;&#1610;&#1601; &#1580;&#1583;&#1575; &#1603;&#1575;&#1606;&#1603; &#1605;&#1608; &#1605;&#1585;&#1603;&#1576; &#1603;&#1601;&#1585; &#1575;&#1576;&#1583;&#1575; &#1604;&#1603;&#1606; &#1601;&#1610;&#1607; &#1605;&#1588;&#1603;&#1604;&#1607; &#1610;&#1578;&#1579;&#1585; &#1576;&#1575;&#1604;&#1576;&#1589;&#1605;&#1575;&#1578; &#1604;&#1603;&#1606; &#1605;&#1587;&#1581;&#1607; &#1582;&#1601;&#1610;&#1601;&#1607; &#1578;&#1606;&#1592;&#1601;&#1607; &#1575;&#1604;&#1581;&#1604;&#1608; &#1601;&#1610;&#1607; &#1606;&#1581;&#1601;&#1607;\n",
      "exception: &#1603;&#1601;&#1585; &#1581;&#1604;&#1608; &#1608;&#1585;&#1582;&#1610;&#1589; &#1608;&#1575;&#1593;&#1580;&#1576; &#1575;&#1607;&#1604;&#1610; &#1580;&#1583;&#1575; &#1580;&#1608;&#1583;&#1578;&#1607; &#1605;&#1578;&#1608;&#1587;&#1591;&#1577; &#1604;&#1575; &#1578;&#1578;&#1608;&#1602;&#1593; &#1588;&#1610; &#1582;&#1610;&#1575;&#1604;&#1610; &#1604;&#1603;&#1606; &#1581;&#1604;&#1608; &#1603;&#1601;&#1585; &#1588;&#1601;&#1575;&#1601; &#1608;&#1605;&#1581;&#1591;&#1608;&#1591; &#1593;&#1604;&#1610;&#1607; &#1575;&#1604;&#1589;&#1608;&#1585;&#1607; &#1575;&#1604;&#1610; &#1601;&#1608;&#1602;\n",
      "exception: &#1575;&#1588;&#1578;&#1585;&#1610;&#1578;&#1607;&#1575; &#1604; &#1586;&#1608;&#1580;&#1578;&#1610;&#1608;&#1575;&#1593;&#1580;&#1576;&#1578;&#1607;&#1575; &#1578;&#1602;&#1608;&#1604; &#1582;&#1575;&#1605;&#1578;&#1607;&#1575; &#1581;&#1604;&#1608;&#1607; &#1608;&#1593;&#1605;&#1604;&#1610;&#1607; &#1601;&#1610;&#1607;&#1575; &#1605;&#1579;&#1604; &#1575;&#1604;&#1580;&#1610;&#1576; &#1604;&#1604;&#1601;&#1604;&#1608;&#1587; &#1575;&#1608; &#1575;&#1604;&#1576;&#1591;&#1575;&#1602;&#1575;&#1578;&#1575;&#1604;&#1578;&#1608;&#1589;&#1610;&#1604; &#1603;&#1575;&#1606; &#1605;&#1605;&#1578;&#1575;&#1586; &#1581;&#1587;&#1576; &#1605;&#1575;&#1607;&#1608; &#1608;&#1575;&#1590;&#1581; &#1601;&#1610; &#1605;&#1593;&#1604;&#1608;&#1605;&#1575;&#1578; &#1575;&#1604;&#1588;&#1581;&#1606;\n",
      "en    193676\n",
      "es       117\n",
      "af        55\n",
      "ro        49\n",
      "so        46\n",
      "de        38\n",
      "ca        19\n",
      "fr        18\n",
      "cy        17\n",
      "et        14\n",
      "sl        14\n",
      "tl        13\n",
      "no        11\n",
      "it        11\n",
      "nl        10\n",
      "sq         9\n",
      "da         8\n",
      "pl         7\n",
      "tr         7\n",
      "vi         7\n",
      "pt         7\n",
      "sk         4\n",
      "hr         4\n",
      "sv         3\n",
      "id         3\n",
      "fi         2\n",
      "cs         2\n",
      "sw         2\n",
      "hu         1\n",
      "Name: LANGUAGE, dtype: int64\n",
      "After removing non-english text: 193676\n",
      "######## OTHER HEURISTICS\n",
      "After removing from other cleaning heuristics:  193675\n",
      "######## PREPROCESSING\n",
      "######## Web Data Specific\n",
      "removed html tags\n",
      "removed hyperlinks\n",
      "removed content between square brackets\n",
      "removed content between angle brackets\n",
      "html unescape done\n",
      "white space removal done\n",
      "language indicator removal done\n",
      "######## Text Harmonization\n",
      "contractions expansion done\n",
      "removed accented characters\n",
      "tokenization done\n",
      "20133514\n",
      "abbreviation transformation done\n",
      "number removal done\n",
      "Token Count:  20022616\n",
      "punctuation and non-ascii removal done\n",
      "Token Count:  18175161\n",
      "######## LOWERCASING STATISTICS\n",
      "Amount of All Capitals words: 301194\n",
      "      Word  Frequency\n",
      "0      USB      25253\n",
      "1        S      22665\n",
      "2        A      17098\n",
      "3        G       7180\n",
      "4      HTC       5894\n",
      "5        T       5208\n",
      "6      LED       4341\n",
      "7      NOT       4238\n",
      "8      OEM       3697\n",
      "9      GPS       3453\n",
      "10     THE       3212\n",
      "11      LG       2989\n",
      "12      IT       2838\n",
      "13      AT       2788\n",
      "14       V       2782\n",
      "15       X       2781\n",
      "16     TPU       2703\n",
      "17      AC       2585\n",
      "18     AND       2565\n",
      "19      HD       2448\n",
      "20      GS       1990\n",
      "21    VERY       1960\n",
      "22       M       1831\n",
      "23      OK       1763\n",
      "24  UPDATE       1731\n",
      "25    THIS       1727\n",
      "26      GB       1710\n",
      "27      II       1676\n",
      "28       C       1670\n",
      "29      MP       1658\n",
      "30       D       1588\n",
      "31      BT       1555\n",
      "32      TO       1554\n",
      "33       N       1529\n",
      "34    LOVE       1508\n",
      "35     SIM       1484\n",
      "36      IS       1482\n",
      "37     EVO       1477\n",
      "38     NFC       1443\n",
      "39      PC       1405\n",
      "40      OS       1283\n",
      "41     BUT       1233\n",
      "42      FM       1189\n",
      "43   GREAT       1185\n",
      "44      SD       1185\n",
      "45      TV       1134\n",
      "46     LTE       1039\n",
      "47      MY       1026\n",
      "48       W       1020\n",
      "49     FOR       1019\n",
      "lowercasing done\n",
      "stopword removal done\n",
      "Token Count:  9224148\n",
      "pos tagging done\n",
      "######## Text Canonicalization\n",
      "port stemming done\n",
      "PREPROCESSING SUMMARY\n",
      "The number of numerics: 312824\n",
      "Numerics as percentage: 1.55% \n",
      "The number of punctuation and non-ascii: 2679204\n",
      "Punctuation and non-ascii as percentage: 13.31% \n",
      "The number of stop words: 7466559\n",
      "Stop words as percentage: 37.09% \n",
      "######## DATA COMPLETION AFTER PREPROCESSING\n",
      "Empty preprocessed text: 2\n",
      "Duplicate preprocessed text: 0.00%\n",
      "After removing empty preprocessed texts:  193673\n",
      "######## DEDUPLICATION AFTER PREPROCESSING\n",
      "Duplicate preprocessed text: 352\n",
      "Duplicate preprocessed text: 0.18%\n",
      "After removing duplicate preprocessed texts:  193321\n",
      "######### LAST CHECK\n",
      "                                                text  label LANGUAGE  \\\n",
      "0  They look good and stick good! I just don't li...    4.0       en   \n",
      "1  These stickers work like the review says they ...    5.0       en   \n",
      "2  These are awesome and make my phone look so st...    5.0       en   \n",
      "3  Item arrived in great time and was in perfect ...    4.0       en   \n",
      "4  awesome! stays on, and looks great. can be use...    5.0       en   \n",
      "\n",
      "                                           text_prep  token_count  \\\n",
      "0  look good stick good not like round shape alwa...           18   \n",
      "1  sticker work like review say stick great stay ...           13   \n",
      "2  awesom make phone look stylish use one far alm...           15   \n",
      "3  item arriv great time perfect condit howev ord...           29   \n",
      "4  awesom stay look great use multipl appl produc...           13   \n",
      "\n",
      "   numerics_mix  punct_non_ascii                                 upper  \\\n",
      "0             0                4                                    []   \n",
      "1             0                5                                    []   \n",
      "2             0                6  [CAN, YOU, BELIEVE, THAT, ONE, YEAR]   \n",
      "3             0                7                                [FREE]   \n",
      "4             0                6                                    []   \n",
      "\n",
      "   stopwords                                                pos  \n",
      "0         16  [(look, VB), (good, JJ), (stick, NN), (good, J...  \n",
      "1         14  [(stickers, NNS), (work, VBP), (like, IN), (re...  \n",
      "2         14  [(awesome, JJ), (make, VBP), (phone, NN), (loo...  \n",
      "3         20  [(item, NN), (arrived, VBD), (great, JJ), (tim...  \n",
      "4         10  [(awesome, JJ), (stays, NNS), (looks, VBZ), (g...  \n",
      "                                                     text          label  \\\n",
      "count                                              193321  193321.000000   \n",
      "unique                                             193321            NaN   \n",
      "top     good divice and give you the exact # OF mAh to...            NaN   \n",
      "freq                                                    1            NaN   \n",
      "mean                                                  NaN       4.128713   \n",
      "std                                                   NaN       1.222746   \n",
      "min                                                   NaN       1.000000   \n",
      "25%                                                   NaN       4.000000   \n",
      "50%                                                   NaN       5.000000   \n",
      "75%                                                   NaN       5.000000   \n",
      "max                                                   NaN       5.000000   \n",
      "\n",
      "       LANGUAGE                                          text_prep  \\\n",
      "count    193321                                             193321   \n",
      "unique        1                                             193321   \n",
      "top          en  light weight almost forget big fan motorola hx...   \n",
      "freq     193321                                                  1   \n",
      "mean        NaN                                                NaN   \n",
      "std         NaN                                                NaN   \n",
      "min         NaN                                                NaN   \n",
      "25%         NaN                                                NaN   \n",
      "50%         NaN                                                NaN   \n",
      "75%         NaN                                                NaN   \n",
      "max         NaN                                                NaN   \n",
      "\n",
      "          token_count   numerics_mix  punct_non_ascii   upper      stopwords  \\\n",
      "count   193321.000000  193321.000000    193321.000000  193321  193321.000000   \n",
      "unique            NaN            NaN              NaN   31650            NaN   \n",
      "top               NaN            NaN              NaN      []            NaN   \n",
      "freq              NaN            NaN              NaN  122962            NaN   \n",
      "mean        47.611248       1.612411        13.826061     NaN      38.541431   \n",
      "std         71.273140       4.745900        24.411220     NaN      56.544466   \n",
      "min          1.000000       0.000000         0.000000     NaN       0.000000   \n",
      "25%         15.000000       0.000000         4.000000     NaN      11.000000   \n",
      "50%         24.000000       0.000000         7.000000     NaN      20.000000   \n",
      "75%         51.000000       2.000000        14.000000     NaN      43.000000   \n",
      "max       3117.000000     293.000000      1392.000000     NaN    2155.000000   \n",
      "\n",
      "                                                      pos  \n",
      "count                                              193321  \n",
      "unique                                             193321  \n",
      "top     [(color, NN), (slightly, RB), (brighter, RB), ...  \n",
      "freq                                                    1  \n",
      "mean                                                  NaN  \n",
      "std                                                   NaN  \n",
      "min                                                   NaN  \n",
      "25%                                                   NaN  \n",
      "50%                                                   NaN  \n",
      "75%                                                   NaN  \n",
      "max                                                   NaN  \n",
      "######## STORING\n",
      "to pickle done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\d064966\\appdata\\local\\continuum\\anaconda3\\envs\\masterthesis\\lib\\site-packages\\pandas\\core\\strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from Scripts import loading as dl, profiling as pf, cleaning as cl, preprocessing as prep\n",
    "\n",
    "\n",
    "input_link = '../Data/reviews_Cell_Phones_and_Accessories_5.json.gz'\n",
    "df = dl.load_amazon_full(input_link)\n",
    "\n",
    "\n",
    "print('######## FIRST GENERAL INSIGHT')\n",
    "print(df.head())\n",
    "pf.get_review_count(df)\n",
    "pf.get_descr(df)\n",
    "\n",
    "\n",
    "print('######## DATA COMPLETENESS')\n",
    "pf.get_missing_text(df)\n",
    "pf.get_missing_label(df)\n",
    "df = cl.proceed_data_completion(df)\n",
    "\n",
    "\n",
    "print('######## DUPLICATE DETECTION')\n",
    "pf.get_duplicates(df)\n",
    "df = cl.drop_duplicates(df)\n",
    "\n",
    "\n",
    "print('######## LINGUISTIC AFFILIATION')\n",
    "df = cl.remove_non_english(df)\n",
    "# pf.show_lang_dist(df, 'amazon_movie_lang_non_eng_dist', 'non-English Language Distribution (Amazon Movies & TV)', 0)\n",
    "# pf.show_lang_dist(df, 'amazon_movie_lang_all_dist', 'Language Distribution (Amazon Movies & TV)', 1)\n",
    "\n",
    "\n",
    "print('######## OTHER HEURISTICS')\n",
    "df = df[~df.text.str.contains(r'^&#((15|16|20)[0-9]{2,3});*')]\n",
    "print('After removing from other cleaning heuristics: ', len(df))\n",
    "\n",
    "\n",
    "print('######## PREPROCESSING')\n",
    "print('######## Web Data Specific')\n",
    "df = prep.remove_html(df)\n",
    "df = prep.remove_hyperlinks(df)\n",
    "df = prep.remove_between_square_brackets(df)\n",
    "df = prep.remove_between_angle_brackets(df)\n",
    "df = prep.unescape(df)\n",
    "df = prep.remove_whitespaces(df)\n",
    "df = prep.remove_lang_ind(df)\n",
    "\n",
    "print('######## Text Harmonization')\n",
    "df = prep.replace_contractions(df)\n",
    "df = prep.remove_accented_chars(df)\n",
    "df = prep.to_token(df)\n",
    "total_token_count = pf.get_total_token_count(df)\n",
    "print(total_token_count)\n",
    "df = prep.transform_abbr(df)\n",
    "df = prep.remove_numbers(df)\n",
    "df = prep.remove_punct_and_nonascii(df)\n",
    "df = prep.to_lower(df)\n",
    "df = prep.remove_stopwords(df)\n",
    "df = prep.get_pos(df)\n",
    "\n",
    "print('######## Text Canonicalization')\n",
    "df = prep.stem(df)\n",
    "\n",
    "pf.get_prep_summary(df, total_token_count)\n",
    "\n",
    "df = prep.detokenize(df)\n",
    "\n",
    "print('######## DATA COMPLETION AFTER PREPROCESSING')\n",
    "total_prep = len(df)\n",
    "df_empty = df[df.text_prep=='']\n",
    "print(\"Empty preprocessed text:\", len(df_empty))\n",
    "print(\"Duplicate preprocessed text: {:.2%}\".format(len(df_empty) / total_prep))\n",
    "df = df[df.text_prep!='']\n",
    "print(\"After removing empty preprocessed texts: \", len(df))\n",
    "\n",
    "print('######## DEDUPLICATION AFTER PREPROCESSING')\n",
    "df_dup = df[df.duplicated(subset=['text_prep'], keep='last')]\n",
    "print(\"Duplicate preprocessed text:\", len(df_dup))\n",
    "print(\"Duplicate preprocessed text: {:.2%}\".format(len(df_dup) / total_prep))\n",
    "df = df.drop_duplicates(subset=['text_prep'], keep='last')\n",
    "print(\"After removing duplicate preprocessed texts: \", len(df))\n",
    "\n",
    "\n",
    "print('######### LAST CHECK')\n",
    "print(df.head())\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "\n",
    "print('######## STORING')\n",
    "df = df[['text','label', 'text_prep', 'token_count', 'upper', 'pos']]\n",
    "df.columns=['text', 'label', 'text_prep', 'token_count', 'upper', 'pos']\n",
    "df.to_pickle('../Data/amazon_phone.pkl')\n",
    "print('to pickle done')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}